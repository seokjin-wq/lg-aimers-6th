{"cells":[{"cell_type":"markdown","metadata":{"id":"qu7nrq41QJiL"},"source":["### Import"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"y3xv7hYGTi4A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0096a55d-7ad6-4b98-e883-8235f73dd88a","executionInfo":{"status":"ok","timestamp":1740571683951,"user_tz":-540,"elapsed":12700,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting category_encoders\n","  Downloading category_encoders-2.8.0-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n","Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n","Downloading category_encoders-2.8.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: category_encoders\n","Successfully installed category_encoders-2.8.0\n","Collecting catboost\n","  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n","Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: catboost\n","Successfully installed catboost-1.2.7\n"]}],"source":["!pip install category_encoders\n","!pip install catboost"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4ey8-1l_QJiO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740571703010,"user_tz":-540,"elapsed":19046,"user":{"displayName":"윤석진","userId":"14953914264612970479"}},"outputId":"44a872aa-33ee-4aac-c85a-bb23c58742a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]}],"source":["import random\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import os\n","import json\n","import re\n","\n","from sklearn.linear_model import (\n","    LogisticRegression\n",")\n","\n","from sklearn.ensemble import (\n","    ExtraTreesClassifier,\n","    RandomForestClassifier\n",")\n","\n","from sklearn.metrics import (\n","    accuracy_score,\n","    confusion_matrix,\n","    f1_score,\n","    precision_score,\n","    recall_score,\n","    roc_auc_score\n",")\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","import category_encoders as ce\n","\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","from xgboost import XGBClassifier\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","import lightgbm as lgb\n","import xgboost as xgb\n","import catboost as cat\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"markdown","metadata":{"id":"I5nWl4UXQJiP"},"source":["### Data Load"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uoab0X_lQRua","outputId":"0db4fe4c-7603-4bf5-f39b-5cb7e67b043b","executionInfo":{"status":"ok","timestamp":1740571725298,"user_tz":-540,"elapsed":22276,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8x1vnRQ8Qwkg","outputId":"a0c506c5-5324-4056-c632-a22045025287","executionInfo":{"status":"ok","timestamp":1740571726524,"user_tz":-540,"elapsed":18,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/MyDrive/Aimers_6th/Data\n"]}],"source":["import os\n","\n","# 현재 작업 디렉터리 출력\n","print(os.getcwd())\n","\n","data_path = os.path.join(os.getcwd(), 'drive', 'MyDrive', 'Aimers_6th', 'Data')\n","print(data_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cljkaVMJCF58","executionInfo":{"status":"ok","timestamp":1740571727532,"user_tz":-540,"elapsed":10,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[],"source":["config = {\n","    'root': data_path\n","    , 'train_path': f'{data_path}/train.csv'\n","    , 'test_path': f'{data_path}/test.csv'\n","    , 'submit_path': f'{data_path}/sample_submission.csv'\n","    , 'seed_list': [42]\n","    , 'k_fold': 5\n","    , 'model': 'lgb'       # cbt, logistic, et, rf, lgb, xgb\n","    , 'encoding': None # None(lgb, xgb, cbt), target, one-hot, ordinal, catboost\n","\n","}"]},{"cell_type":"markdown","metadata":{"id":"SKK9T6wdC7tq"},"source":["### HyperParameter"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FM3otssjC-ur","executionInfo":{"status":"ok","timestamp":1740571771474,"user_tz":-540,"elapsed":40,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[],"source":["# Our best parameters\n","params_di = {\n","    'logistic': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'max_iter': 300,\n","        'penalty': 'l2'\n","    },\n","\n","    'et': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        'max_samples': 0.5\n","\n","    },\n","\n","    'rf': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        # 'max_samples': 0.5,\n","        'bootstrap': False,\n","\n","    },\n","\n","    'lgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary',\n","        'n_jobs': 1,\n","        'verbosity': -1,\n","        'early_stopping_rounds': 10,\n","        'deterministic': True,\n","        'n_estimators': 399,\n","        'learning_rate': 0.08662393386614221,\n","        'num_leaves': 30,\n","        'max_depth': 7,\n","        'min_child_samples': 9,\n","        'subsample': 0.8712444912002683,\n","        'colsample_bytree': 0.7028171113108472,\n","        'reg_alpha': 3.2093670445847933e-05,\n","        'reg_lambda': 7.779128043413825,\n","\n","    },\n","\n","    'xgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'auc',\n","        'n_jobs': 1,\n","        'early_stopping_rounds': 10,\n","        'learning_rate': 0.1,\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'reg_lambda': 1,\n","        'subsample': 0.5,\n","        'enable_categorical': True,\n","        'tree_method': 'hist'\n","\n","    },\n","\n","    'cbt': {\n","        'random_seed': config['seed_list'][0],\n","        'objective': 'Logloss',\n","        'eval_metric': 'AUC',\n","        'auto_class_weights': 'Balanced',\n","        'verbose': 100,\n","        'early_stopping_rounds': 10,\n","        'learning_rate': 0.1,\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'l2_leaf_reg': 1,\n","        'min_data_in_leaf': 2,\n","        'subsample': 0.5,\n","        'task_type': 'CPU',\n","        'allow_writing_files': False\n","    }\n","}\n","\n","params_ivf = {\n","    'logistic': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'max_iter': 300,\n","        'penalty': 'l2'\n","    },\n","\n","    'et': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        'max_samples': 0.5\n","\n","    },\n","\n","    'rf': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        # 'max_samples': 0.5,\n","        'bootstrap': False,\n","\n","    },\n","\n","    # 'lgb': {\n","    #     'random_state': config['seed_list'][0],\n","    #     'objective': 'binary',\n","    #     'n_jobs': 1,\n","    #     'verbosity': -1,\n","    #     'early_stopping_rounds': 10,\n","    #     'n_estimators': 300,\n","    #     'learning_rate': 0.1,\n","    #     'max_depth': 6,\n","    #     'reg_lambda': 1,\n","    #     'subsample': 0.5,\n","    #     'deterministic': True,\n","    # },\n","\n","    'lgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary',\n","        'n_jobs': 1,\n","        'verbosity': -1,\n","        'early_stopping_rounds': 10,\n","        'deterministic': True,\n","        'n_estimators': 748,\n","        'learning_rate': 0.08840853796420356,\n","        'num_leaves': 64,\n","        'max_depth': 5,\n","        'min_child_samples': 58,\n","        'subsample': 0.7448154771558511,\n","        'colsample_bytree': 0.390303271980168,\n","        'reg_alpha': 9.85421725516684,\n","        'reg_lambda': 0.0011651450136949582,\n","\n","    },\n","\n","    'xgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'auc',\n","        'n_jobs': 1,\n","        'early_stopping_rounds': 10,\n","        'learning_rate': 0.1,\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'reg_lambda': 1,\n","        'subsample': 0.5,\n","        'enable_categorical': True,\n","        'tree_method': 'hist'\n","\n","    },\n","\n","    'cbt': {\n","        'random_seed': config['seed_list'][0],\n","        'objective': 'Logloss',\n","        'eval_metric': 'AUC',\n","        'auto_class_weights': 'Balanced',\n","        'verbose': 100,\n","        'early_stopping_rounds': 10,\n","        'learning_rate': 0.1,\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'l2_leaf_reg': 1,\n","        'min_data_in_leaf': 2,\n","        'subsample': 0.5,\n","        'task_type': 'CPU',\n","        'allow_writing_files': False\n","    }\n","}"]},{"cell_type":"markdown","metadata":{"id":"gwV9ZY6PDFoi"},"source":["### Function"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"0D-Kj4MNDKIC","executionInfo":{"status":"ok","timestamp":1740571776058,"user_tz":-540,"elapsed":367,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[],"source":["def set_seed(seed: int):\n","    # Set the seed for reproducibility.\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","\n","\n","def read_data(config):\n","    # Load training, testing, and submission CSV files\n","    df_train = pd.read_csv(config['train_path']).drop(columns=['ID'])  # train data\n","    df_test = pd.read_csv(config['test_path']).drop(columns=['ID'])    # test data\n","    df_sub = pd.read_csv(config['submit_path'])\n","\n","    print(f'train data 수: {df_train.shape[0]}')\n","    print(f'test data 수: {df_test.shape[0]}')\n","    print(f'submission data 수: {df_sub.shape[0]}')\n","    return df_train, df_test, df_sub\n","\n","def df_ivf_di_split(df, is_train=False):\n","\n","    data_type = 'train' if is_train else 'test'\n","\n","    print(f'data 수: {df.shape[0]}')\n","\n","    df_ivf = df[df['시술 유형'] == 'IVF'].drop(columns=['시술 유형'])\n","    df_di = df[df['시술 유형'] == 'DI'].drop(columns=['시술 유형'])\n","\n","    print(f'시술유형 IVF {data_type} data 수: {df_ivf.shape[0]}')\n","    print(f'시술유형 DI {data_type} data 수: {df_di.shape[0]}')\n","\n","    return df_ivf, df_di\n","\n","# 분류 모델의 성능을 평가하는 것들 표시\n","def get_clf_eval(y_test, y_proba=None, fold_no=None):\n","    # Calculate and print evaluation metrics and confusion matrix,\n","    # accuracy, precision, recall, f1 and roc_auc score.\n","    # Optionally includes fold number in the output.\n","\n","    # 임계값 0.5 기준 예측값 생성\n","    y_pred = (y_proba >= 0.5).astype(int)\n","\n","    y_test = y_test.values\n","\n","    confusion = confusion_matrix(y_test, y_pred)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    roc_auc = roc_auc_score(y_test, y_proba)  # ROC-AUC는 확률값 그대로 사용\n","\n","    fold_info = f'Fold #{fold_no}' if fold_no is not None else ''\n","    print(f'{fold_info} ACC: {accuracy:.4f}, PRE: {precision:.4f}, REC: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}')\n","    return roc_auc\n","\n","\n","# Categorical variable encoding method.(카테고리 변수 인코딩)\n","def category_encoding(df_train, df_test, base_num_features, base_cat_features, config, is_ivf=False):\n","    target = '임신 성공 여부'\n","\n","    data_name = 'IVF' if is_ivf else 'DI'\n","\n","    new_df_train = pd.concat([df_train[base_num_features].copy(), df_train[target]], axis = 1)\n","    new_df_test = df_test[base_num_features].copy()\n","\n","    print(f'{data_name} category 변수 인코딩: {config[\"encoding\"]}')\n","\n","    if config['encoding'] == 'target':\n","        encoder = ce.TargetEncoder(cols=base_cat_features)\n","\n","    elif config['encoding'] == 'ordinal':\n","        encoder = ce.OrdinalEncoder(cols=base_cat_features)\n","\n","    elif config['encoding'] == 'catboost':\n","        encoder = ce.CatBoostEncoder(cols=base_cat_features)#, random_state=config['seed'])\n","\n","    if config['encoding'] in ['target', 'ordinal', 'catboost']:\n","        encoder.fit(df_train[base_cat_features], df_train[target])\n","        new_df_train[base_cat_features] = encoder.transform(df_train[base_cat_features])\n","        new_df_test[base_cat_features] = encoder.transform(df_test[base_cat_features])\n","\n","    elif config['encoding'] == 'one-hot':\n","        encoder = ce.OneHotEncoder(cols=base_cat_features, use_cat_names = True)\n","        encoder.fit(df_train[base_cat_features], df_train[target])\n","        result_tr = encoder.transform(df_train[base_cat_features])\n","        result_te = encoder.transform(df_test[base_cat_features])\n","\n","        result_tr.columns = result_tr.columns.str.replace(r'[^ㄱ-ㅎ가-힣A-Za-z0-9_]', '_', regex=True)\n","        result_te.columns = result_te.columns.str.replace(r'[^ㄱ-ㅎ가-힣A-Za-z0-9_]', '_', regex=True)\n","\n","        new_df_train = pd.concat([new_df_train, result_tr], axis = 1)\n","        new_df_test = pd.concat([new_df_test, result_te], axis = 1)\n","\n","    elif config['encoding'] is None:\n","        new_df_train = pd.concat([new_df_train, df_train[base_cat_features]], axis = 1)\n","        new_df_test = pd.concat([new_df_test, df_test[base_cat_features]], axis = 1)\n","\n","    _, base_cat_features, base_features = make_feature_lists(new_df_train, is_ivf=is_ivf)\n","\n","    return new_df_train, new_df_test, base_cat_features, base_features\n","\n","def feature_engineering(df_input, tr_removed_column_list, is_train=False, is_ivf=False):\n","    df = df_input.copy()\n","\n","    data_name = 'IVF' if is_ivf else 'DI'\n","    data_type = 'train' if is_train else 'test'\n","\n","    if is_train:\n","        removed_column_list = []\n","    else:\n","        removed_column_list = tr_removed_column_list\n","\n","\n","    print(f'중복 제거 전 {data_type} {data_name} data 수: {df.shape[0]}')\n","\n","    # drop_duplicates\n","    df = df.drop_duplicates(keep='first')\n","\n","    print(f'중복 제거 후 {data_type} {data_name} data 수: {df.shape[0]}')\n","\n","    # 횟수 관련 column\n","    count_columns = [column for column in df.columns if '횟수' in column]\n","\n","    for col in count_columns:\n","        df[col] = df[col].str.replace('회', '').str.replace('이상', '').str.replace(' ', '').astype(int)\n","\n","\n","    # 시술 당시 나이 범위를 중앙값으로 변환하는 매핑 딕셔너리 (누락된 범위 추가)\n","    treatment_age = {\n","        \"만18-34세\": 26,\n","        \"만35-37세\": 36,\n","        \"만38-39세\": 38.5,\n","        \"만40-42세\": 41,\n","        \"만43-44세\": 43.5,\n","        \"만45-50세\": 47.5,\n","        \"알 수 없음\": -1  # 알 수 없음은 -1로 처리\n","    }\n","\n","    # 공백 제거 후 매핑\n","    # 시술 당시 나이 숫자 mapping -> DI에만 적용\n","    if is_ivf:\n","        df[\"시술 당시 나이\"] = df[\"시술 당시 나이\"].str.strip().map(treatment_age).astype(float)\n","\n","    # # 정자 난자기증자 나이 범위를 중앙값으로 변환하는 매핑 딕셔너리 (누락된 범위 추가)\n","    donor_age = {\n","        \"만20세 이하\": 20,\n","        \"만21-25세\": 23,\n","        \"만26-30세\": 28,\n","        \"만31-35세\": 33,\n","        \"만36-40세\": 38,\n","        \"만41-45세\": 43,\n","        \"알 수 없음\": -1 # 알 수 없음은 -1로 처리\n","    }\n","\n","    # 공백 제거 후 매핑\n","    if is_ivf:\n","        df[\"난자 기증자 나이\"] = df[\"난자 기증자 나이\"].str.strip().map(donor_age).astype(float)\n","\n","    df[\"정자 기증자 나이\"] = df[\"정자 기증자 나이\"].str.strip().map(donor_age).astype(float)\n","\n","    # 특정 시술 유형\n","    treat_types = []\n","    # embryo_creation_reasons = []\n","\n","    if not is_ivf:\n","        treat_types.extend(['IUI', 'ICI', 'Generic DI', 'IVI'])\n","\n","    if is_ivf:\n","        treat_types.extend(['ICSI', 'IVF', 'BLASTOCYST', 'AH', 'Unknown'])\n","        # embryo_creation_reasons.extend(['현재 시술용', '배아 저장용', '기증용', '난자 저장용'])\n","\n","    # 각 target에 대한 Multi-Hot Encoding 및 Count 계산\n","    for treat_type in treat_types:\n","        # 각 행에서 target이 등장하는 횟수 계산\n","        df[treat_type] = df['특정 시술 유형'].str.count(treat_type)\n","\n","    # if is_ivf:\n","    #     for embryo_creation_reason in embryo_creation_reasons:\n","    #         # 각 행에서 target이 등장하는 횟수 계산\n","    #         df[embryo_creation_reason] = df['배아 생성 주요 이유'].str.count(embryo_creation_reason)\n","\n","    df_column_list = df.columns\n","    print(f'column 제거 전 {data_type} {data_name} data shape: {df.shape}')\n","\n","    if is_train:\n","        # train data에서 전부 결측치거나 값 1개만 갖는 column 제거\n","\n","        for feat in df_column_list:\n","\n","            null_count = df[feat].isna().sum() # feat 열 결측치 수\n","\n","            if df[feat].nunique() == 0 or (df[feat].nunique() == 1 and null_count == 0):\n","                df = df.drop(columns=[feat])\n","                removed_column_list.append(feat)\n","\n","\n","    # # test data에서는 train data에서 제거된 column 제거\n","    else:\n","\n","        df = df.drop(columns=removed_column_list)\n","\n","    print(f'column 제거 후 {data_type} {data_name} data shape: {df.shape}')\n","\n","    # 파생변수 생성\n","    # IVF에만 존재하는 피처\n","    if is_ivf:\n","        # 비율 및 비율 차이\n","        df[\"배아_생성률\"] = df[\"미세주입에서 생성된 배아 수\"] / (df[\"미세주입된 난자 수\"] + 1e-5)\n","        df[\"배아_이식률\"] = df[\"이식된 배아 수\"] / (df[\"총 생성 배아 수\"] + 1e-5)\n","        df[\"미세주입_이식률\"] = df[\"미세주입 배아 이식 수\"] / (df[\"미세주입에서 생성된 배아 수\"] + 1e-5)\n","        df[\"배아_저장률\"] = df[\"저장된 배아 수\"] / (df[\"총 생성 배아 수\"] + 1e-5)\n","        df[\"배아_해동률\"] = df[\"해동된 배아 수\"] / (df[\"저장된 배아 수\"] + 1e-5)\n","        df[\"기증자_정자_비율\"] = df[\"기증자 정자와 혼합된 난자 수\"] / (df[\"혼합된 난자 수\"] + 1e-5)\n","        df[\"배아_손실률\"] = 1 - (df[\"미세주입에서 생성된 배아 수\"] / (df[\"미세주입된 난자 수\"] + 1e-5))\n","        df[\"배아_이식_대비_해동된_배아_비율\"] = df[\"해동된 배아 수\"] / (df[\"이식된 배아 수\"] + 1e-5)\n","        df[\"미세주입_비율\"] = df[\"미세주입된 난자 수\"] / (df[\"총 생성 배아 수\"] + 1e-5)\n","        df[\"신선_난자_저장률\"] = df[\"저장된 신선 난자 수\"] / (df[\"수집된 신선 난자 수\"] + 1e-5)\n","        df[\"정자_혼합_비율_차이\"] = (\n","            df[\"파트너 정자와 혼합된 난자 수\"] / (df[\"혼합된 난자 수\"] + 1e-5)\n","            - df[\"기증자 정자와 혼합된 난자 수\"] / (df[\"혼합된 난자 수\"] + 1e-5)\n","        )\n","\n","        # 차이 및 변화량\n","        df[\"미세주입_실패_수\"] = df[\"미세주입된 난자 수\"] - df[\"미세주입에서 생성된 배아 수\"]\n","        df[\"이식되지_않은_배아_수\"] = df[\"미세주입에서 생성된 배아 수\"] - df[\"미세주입 배아 이식 수\"]\n","        df[\"저장되지_않은_신선_난자_수\"] = df[\"수집된 신선 난자 수\"] - df[\"저장된 신선 난자 수\"]\n","        df[\"기증자_혼합_난자_수\"] = df[\"혼합된 난자 수\"] - df[\"파트너 정자와 혼합된 난자 수\"]\n","        df[\"해동_후_이식_까지_시간\"] = df[\"배아 이식 경과일\"] - df[\"배아 해동 경과일\"]\n","        df[\"해동_후_미세주입_성공률\"] = df[\"미세주입된 난자 수\"] / (df[\"해동된 배아 수\"] + 1e-5)\n","        # df[\"배아_생성_감소량\"] = df[\"미세주입된 난자 수\"] - df[\"미세주입에서 생성된 배아 수\"]\n","        # df[\"배아_해동_후_남은_기간\"] = df[\"배아 이식 경과일\"] - df[\"배아 해동 경과일\"]\n","        df[\"배아_저장_후_해동_기간\"] = df[\"배아 해동 경과일\"] - df[\"난자 혼합 경과일\"]\n","        df[\"정자_혼합_후_배아_생성_경과일\"] = df[\"배아 이식 경과일\"] - df[\"난자 혼합 경과일\"]\n","        # df[\"미세주입_대비_해동된_배아_비율\"] = df[\"미세주입된 난자 수\"] / (df[\"해동된 배아 수\"] + 1e-5)\n","\n","    # 불임 원인 multi hot -> 하나의 feature\n","\n","    # infertility_columns = [column for column in df.columns if '불임 원인' in column]\n","\n","    # # dot()을 사용하여 1이 있는 컬럼을 결합 (각 feature 사이에 공백 추가)\n","    # df['불임 원인 종합'] = df[infertility_columns].dot(pd.Index([f'{col.replace(\"불임 원인\", \"\").replace(\" \", \"\")} ' for col in infertility_columns])).str.strip()\n","\n","    # # 한글만 남기고 나머지 문자 제거 (정규 표현식 사용)\n","    # df['불임 원인 종합'] = df['불임 원인 종합'].apply(lambda x: re.sub(r'[^가-힣 ]', '', x))\n","\n","    # # split()과 join()을 사용하여 공백을 ','로 변경\n","    # df['불임 원인 종합'] = df['불임 원인 종합'].apply(lambda x: ', '.join(x.split()))\n","\n","    # df = df.drop(columns=infertility_columns)\n","\n","    return df, removed_column_list\n","\n","def make_feature_lists(df, is_ivf=False):\n","    base_features = []     # all features except target variable.\n","    base_num_features = [] # numerical features\n","    base_cat_features = [] # categorical features\n","\n","    data_name = 'IVF' if is_ivf else 'DI'\n","\n","    for feat in df.columns:\n","        # skip the target\n","        if feat == '임신 성공 여부':\n","            continue\n","\n","        base_features.append(feat)\n","\n","        if df[feat].dtype in ['object', 'category']:\n","            base_cat_features.append(feat)\n","        else:\n","            base_num_features.append(feat)\n","\n","    # infertility_columns = [column for column in df.columns if '불임 원인' in column]\n","\n","    # 공통 제거 변수\n","    removal_features = {\n","            'ID', '불임 원인 - 여성 요인', '불임 원인 - 정자 면역학적 요인', '불임 원인 - 자궁경부 문제',\n","            '시술 유형', '배란 유도 유형', '특정 시술 유형','배란 자극 여부','부부 주 불임 원인','여성 주 불임 원인'}\n","\n","    # ivf 제거 변수\n","    removal_features_ivf = {\n","        '남성 주 불임 원인', '남성 부 불임 원인','부부 부 불임 원인','AH','신선_난자 저장률','IVF',\n","        '저장된 신선 난자 수', '신선 배아 사용 여부', '대리모 여부','난자 해동 경과일','DI 임신 횟수','불임 원인 - 정자 농도',\n","        '동결 배아 사용 여부','배아_저장_후_해동_기간','불임 원인 - 정자 운동성','DI 출산 횟수',\n","        '불임 원인 - 정자 형태', '기증 배아 사용 여부','배아 해동 경과일'\n","    }\n","\n","    # di 제거 변수\n","    removal_features_di = {\n","        '불임 원인- 배란 장애','불명확 불임 원인',' 임신 시도 또는 마지막 임신 경과 연수','총 출산 횟수',\n","        '총 임신 횟수','시술 시기 코드','클리닉 내 총 시술 횟수'\n","    }\n","    if is_ivf:\n","        removal_features = removal_features.union(removal_features_ivf)\n","    else:\n","        removal_features = removal_features.union(removal_features_di)\n","\n","    # removal_features.update(infertility_columns)\n","\n","    # remove the specified features\n","    base_num_features = [i for i in base_num_features if i not in removal_features]\n","    base_cat_features = [i for i in base_cat_features if i not in removal_features]\n","    base_features = [i for i in base_features if i not in removal_features]\n","\n","    print(f'{data_name} numeric feature 수: {len(base_num_features)}')\n","    print(f'{data_name} category feature 수: {len(base_cat_features)}')\n","    print(f'{data_name} 전체 feature 수: {len(base_features)}')\n","\n","    return base_num_features, base_cat_features, base_features\n","\n","def filling_missing_values(df_input, base_cat_features, base_num_features, config):\n","    df = df_input.copy()\n","\n","    # Fill missing values for categorical features with 'Unknown' and ensure their data type is string.\n","    for base_cat_feat in base_cat_features:\n","        df[base_cat_feat] = df[base_cat_feat].astype(str)\n","        df[base_cat_feat] = df[base_cat_feat].fillna('알 수 없음')\n","\n","        if config['encoding'] is None:\n","            df[base_cat_feat] = df[base_cat_feat].astype('category')\n","\n","\n","    # Fill missing values for numerical features with -1.\n","    for base_num_feat in base_num_features:\n","        df[base_num_feat] = df[base_num_feat].fillna(-1)\n","\n","    return df\n","\n","\n","import lightgbm as lgb\n","import xgboost as xgb\n","import catboost as cat\n","from lightgbm import early_stopping\n","\n","def model_kfold(df, config, params, base_features):\n","    target = '임신 성공 여부'\n","    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=config['seed'])\n","    models = []\n","    roc_auc_scores = []\n","\n","    for train_idx, valid_idx in skf.split(df[base_features], df[target]):\n","        X_train, y_train = df[base_features].iloc[train_idx], df[target].iloc[train_idx]\n","        X_valid, y_valid = df[base_features].iloc[valid_idx], df[target].iloc[valid_idx]\n","\n","        model_params = params[config['model']]  # IVF와 DI의 하이퍼파라미터를 분리하여 적용\n","\n","        if config['model'] == 'stacking':\n","            base_models = [\n","                ('lgbm', lgb.LGBMClassifier(**params['lgb'])),\n","                ('xgb', xgb.XGBClassifier(**params['xgb'])),\n","                ('catboost', cat.CatBoostClassifier(**params['cbt'], verbose=0))\n","            ]\n","\n","            meta_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.05)\n","            model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=3)\n","\n","        elif config['model'] == 'lgb':\n","            model = lgb.LGBMClassifier(**model_params)\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                eval_metric='auc',\n","                callbacks=[lgb.early_stopping(10, verbose=False)]\n","            )\n","\n","        elif config['model'] == 'xgb':\n","            model = xgb.XGBClassifier(**model_params)\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                eval_metric='auc',\n","                early_stopping_rounds=10,\n","                verbose=False\n","            )\n","\n","        elif config['model'] == 'cbt':\n","            model = cat.CatBoostClassifier(**model_params, verbose=0)\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                early_stopping_rounds=10,\n","                verbose=False\n","            )\n","\n","        else:\n","            raise ValueError(f\"Unsupported model type: {config['model']}\")\n","\n","        models.append(model)\n","        y_prob = model.predict_proba(X_valid)[:, 1]\n","        roc_auc = get_clf_eval(y_valid, y_prob)\n","        roc_auc_scores.append(roc_auc)\n","\n","    avg_roc_auc = np.mean(roc_auc_scores)\n","    var_roc_auc = np.var(roc_auc_scores)\n","\n","    return models, avg_roc_auc, var_roc_auc\n","\n","\n","\n","def kfold_submission(df_test_ivf, df_test_di, df_sub, models_ivf, models_di, config):\n","    feat_importance_path = f\"{config['root']}/FeatureImportance\"\n","    submission_path = f\"{config['root']}/Submission\"\n","    json_path = f\"{config['root']}/Json\"\n","\n","    if not os.path.exists(feat_importance_path):\n","        os.makedirs(feat_importance_path)\n","\n","    if not os.path.exists(submission_path):\n","        os.makedirs(submission_path)\n","\n","    if not os.path.exists(json_path):\n","        os.makedirs(json_path)\n","\n","    # get current date and time\n","    now = datetime.now()\n","\n","    # record the year, month, day, hour, and minute for naming files.\n","    year = now.year\n","    month = now.month\n","    day = now.day\n","    hour = now.hour\n","    minute = now.minute\n","\n","    # file format\n","    submission_time = f\"{year:04d}{month:02d}{day:02d}_{hour:02d}{minute:02d}\"[2:]\n","    target = 'probability'\n","\n","    # apply feature engineering\n","    base_num_features_ivf, base_cat_features_ivf, base_features_ivf = make_feature_lists(df_test_ivf, is_ivf=True)\n","    df_test_ivf = filling_missing_values(df_test_ivf, base_cat_features_ivf, base_num_features_ivf, config)\n","    X_test_ivf = df_test_ivf[base_features_ivf]\n","\n","    base_num_features_di, base_cat_features_di, base_features_di = make_feature_lists(df_test_di, is_ivf=False)\n","    df_test_di = filling_missing_values(df_test_di, base_cat_features_di, base_num_features_di, config)\n","    X_test_di = df_test_di[base_features_di]\n","\n","    # dataframe for feature importances\n","    base_features = list(set(base_features_ivf).union(set(base_features_di)))\n","\n","    df_feature_importance_all_ivf = pd.DataFrame({'features': base_features_ivf})\n","    df_feature_importance_all_di = pd.DataFrame({'features': base_features_di})\n","\n","    y_probs_ivf = 0\n","    y_probs_di = 0\n","\n","    for i, model_ivf in enumerate(models_ivf):\n","        y_probs_ivf += model_ivf.predict_proba(X_test_ivf)[:, 1] / len(models_ivf)\n","\n","        # save feature importance of current model\n","        if config['model'] in ['logistic']:\n","            df_feature_importance_all_ivf[f'model_{i}'] = model_ivf.coef_.squeeze()\n","\n","        elif config['model'] in ['et', 'rf', 'lgb', 'xgb']:\n","            df_feature_importance_all_ivf[f'model_{i}'] = model_ivf.feature_importances_\n","\n","        elif config['model'] == 'cbt':\n","            df_feature_importance_all_ivf[f'model_{i}'] = model_ivf.get_feature_importance()\n","\n","    for i, model_di in enumerate(models_di):\n","        y_probs_di += model_di.predict_proba(X_test_di)[:, 1] / len(models_di)\n","\n","        # save feature importance of current model\n","        if config['model'] in ['logistic']:\n","            df_feature_importance_all_di[f'model_{i}'] = model_di.coef_.squeeze()\n","\n","        elif config['model'] in ['et', 'rf', 'lgb', 'xgb']:\n","            df_feature_importance_all_di[f'model_{i}'] = model_di.feature_importances_\n","\n","        elif config['model'] == 'cbt':\n","            df_feature_importance_all_di[f'model_{i}'] = model_di.get_feature_importance()\n","\n","    df_sub.loc[df_test_ivf.index, target] = y_probs_ivf\n","    df_sub.loc[df_test_di.index, target] = y_probs_di\n","\n","    # save submission file as CSV\n","    df_sub.to_csv(f\"{submission_path}/{submission_time}_{config['model']}_{config['encoding']}_submission.csv\", index=False)\n","\n","    # compute avarege, rank\n","    df_feature_importance_all_ivf['average'] = df_feature_importance_all_ivf.iloc[:, 1:].mean(axis=1).values\n","    df_feature_importance_all_ivf['rank'] = df_feature_importance_all_ivf['average'].rank(ascending=False)\n","    df_feature_importance_all_ivf = df_feature_importance_all_ivf.sort_values(by='rank')\n","\n","    df_feature_importance_all_di['average'] = df_feature_importance_all_di.iloc[:, 1:].mean(axis=1).values\n","    df_feature_importance_all_di['rank'] = df_feature_importance_all_di['average'].rank(ascending=False)\n","    df_feature_importance_all_di = df_feature_importance_all_di.sort_values(by='rank')\n","\n","    # save the feature importance as CSV\n","    df_feature_importance_all_ivf.to_csv(f'{feat_importance_path}/feat_import_{submission_time}_{config[\"model\"]}_IVF_{config[\"encoding\"]}.csv', index=False)\n","    df_feature_importance_all_di.to_csv(f'{feat_importance_path}/feat_import_{submission_time}_{config[\"model\"]}_DI_{config[\"encoding\"]}.csv', index=False)\n","\n","    # save parameters as JSON\n","    json_data = json.dumps(config, indent=4)\n","\n","    with open(f'{json_path}/{submission_time}_{config[\"model\"]}_{config[\"encoding\"]}.json', 'w') as file:\n","        file.write(json_data)"]},{"cell_type":"markdown","metadata":{"id":"3d4zUcXXQJiQ"},"source":["### Data Pre-processing"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"7wSJYvkYESQv","executionInfo":{"status":"ok","timestamp":1740571964694,"user_tz":-540,"elapsed":5,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[],"source":["def main(config, params_di, params_ivf):\n","    models_ivf = []\n","    models_di = []\n","\n","    for seed in config['seed_list']:\n","        config['seed'] = seed\n","        params_di['random_seed'] = seed\n","        params_ivf['random_seed'] = seed\n","\n","        # set seed\n","        set_seed(config['seed'])\n","\n","        # read data set\n","        df_train, df_test, df_sub = read_data(config)\n","\n","        # ivf di split\n","        df_train_ivf, df_train_di = df_ivf_di_split(df_train, is_train=True)\n","        df_test_ivf, df_test_di = df_ivf_di_split(df_test, is_train=False)\n","\n","        # feature engineering (train,test)\n","        df_train_ivf, removed_column_list_ivf = feature_engineering(df_train_ivf, None, is_train=True, is_ivf=True)\n","        df_test_ivf, _ = feature_engineering(df_test_ivf, removed_column_list_ivf, is_train=False, is_ivf=True)\n","\n","        df_train_di, removed_column_list_di = feature_engineering(df_train_di, None, is_train=True, is_ivf=False)\n","        df_test_di, _ = feature_engineering(df_test_di, removed_column_list_di, is_train=False, is_ivf=False)\n","\n","        # feature list 생성 (train)\n","        base_num_features_ivf, base_cat_features_ivf, base_features_ivf = make_feature_lists(df_train_ivf, is_ivf=True)\n","        base_num_features_di, base_cat_features_di, base_features_di = make_feature_lists(df_train_di, is_ivf=False)\n","\n","        # 결측치 처리\n","        df_train_ivf = filling_missing_values(df_train_ivf, base_cat_features_ivf, base_num_features_ivf, config)\n","        df_train_di = filling_missing_values(df_train_di, base_cat_features_di, base_num_features_di, config)\n","\n","        # encoding\n","        df_train_ivf, df_test_ivf, base_cat_features_ivf, base_features_ivf = category_encoding(\n","            df_train_ivf, df_test_ivf, base_num_features_ivf, base_cat_features_ivf, config, is_ivf=True\n","        )\n","        df_train_di, df_test_di, base_cat_features_di, base_features_di = category_encoding(\n","            df_train_di, df_test_di, base_num_features_di, base_cat_features_di, config, is_ivf=False\n","        )\n","\n","        # IVF와 DI에 각각 다른 파라미터 전달\n","        model_ivf, avg_roc_auc_ivf, var_roc_auc_ivf = model_kfold(df_train_ivf, config, params_ivf, base_features_ivf)\n","        model_di, avg_roc_auc_di, var_roc_auc_di = model_kfold(df_train_di, config, params_di, base_features_di)\n","\n","        config['avg_roc_auc_ivf'] = avg_roc_auc_ivf\n","        config['var_roc_auc_ivf'] = var_roc_auc_ivf\n","\n","        config['avg_roc_auc_di'] = avg_roc_auc_di\n","        config['var_roc_auc_di'] = var_roc_auc_di\n","\n","        models_ivf.extend(model_ivf)\n","        models_di.extend(model_di)\n","\n","    config['model_param_di'] = params_di[config['model']]\n","    config['model_param_ivf'] = params_ivf[config['model']]\n","\n","    # submission\n","    kfold_submission(df_test_ivf, df_test_di, df_sub, models_ivf, models_di, config)\n","\n","    print(\"\\n **모델 평가 결과**\")\n","    print(f\"Avg. roc-auc of validset IVF: {config['avg_roc_auc_ivf']:.6f}\")\n","    print(f\"Var. roc-auc of validset IVF: {config['var_roc_auc_ivf']:.6f}\")\n","    print(f\"Avg. roc-auc of validset DI: {config['avg_roc_auc_di']:.6f}\")\n","    print(f\"Var. roc-auc of validset DI: {config['var_roc_auc_di']:.6f}\\n\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NaZgJXIyEVDj","outputId":"c04d0f66-4221-401b-e255-2220f2dd996c","executionInfo":{"status":"ok","timestamp":1740572026634,"user_tz":-540,"elapsed":59446,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["train data 수: 256351\n","test data 수: 90067\n","submission data 수: 90067\n","data 수: 256351\n","시술유형 IVF train data 수: 250060\n","시술유형 DI train data 수: 6291\n","data 수: 90067\n","시술유형 IVF test data 수: 87891\n","시술유형 DI test data 수: 2176\n","중복 제거 전 train IVF data 수: 250060\n","중복 제거 후 train IVF data 수: 250060\n","column 제거 전 train IVF data shape: (250060, 72)\n","column 제거 후 train IVF data shape: (250060, 71)\n","중복 제거 전 test IVF data 수: 87891\n","중복 제거 후 test IVF data 수: 87891\n","column 제거 전 test IVF data shape: (87891, 71)\n","column 제거 후 test IVF data shape: (87891, 70)\n","중복 제거 전 train DI data 수: 6291\n","중복 제거 후 train DI data 수: 6291\n","column 제거 전 train DI data shape: (6291, 71)\n","column 제거 후 train DI data shape: (6291, 34)\n","중복 제거 전 test DI data 수: 2176\n","중복 제거 후 test DI data 수: 2176\n","column 제거 전 test DI data shape: (2176, 70)\n","column 제거 후 test DI data shape: (2176, 33)\n","IVF numeric feature 수: 60\n","IVF category feature 수: 4\n","IVF 전체 feature 수: 64\n","DI numeric feature 수: 23\n","DI category feature 수: 1\n","DI 전체 feature 수: 24\n","IVF category 변수 인코딩: None\n","IVF numeric feature 수: 60\n","IVF category feature 수: 4\n","IVF 전체 feature 수: 64\n","DI category 변수 인코딩: None\n","DI numeric feature 수: 23\n","DI category feature 수: 1\n","DI 전체 feature 수: 24\n"," ACC: 0.7439, PRE: 0.5479, REC: 0.1202, F1: 0.1971, ROC-AUC: 0.7396\n"," ACC: 0.7432, PRE: 0.5406, REC: 0.1219, F1: 0.1989, ROC-AUC: 0.7372\n"," ACC: 0.7415, PRE: 0.5291, REC: 0.1096, F1: 0.1817, ROC-AUC: 0.7366\n"," ACC: 0.8712, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.6787\n"," ACC: 0.8712, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.6749\n"," ACC: 0.8708, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.7011\n","IVF numeric feature 수: 60\n","IVF category feature 수: 4\n","IVF 전체 feature 수: 64\n","DI numeric feature 수: 23\n","DI category feature 수: 1\n","DI 전체 feature 수: 24\n","\n"," **모델 평가 결과**\n","Avg. roc-auc of validset IVF: 0.737799\n","Var. roc-auc of validset IVF: 0.000002\n","Avg. roc-auc of validset DI: 0.684907\n","Var. roc-auc of validset DI: 0.000134\n","\n"]}],"source":["main(config, params_di, params_ivf)"]},{"cell_type":"code","source":[],"metadata":{"id":"a03wwG4bAkNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read data set\n","df_train, df_test, df_sub = read_data(config)\n","\n","# ivf di split\n","df_train_ivf, df_train_di = df_ivf_di_split(df_train, is_train = True)\n","df_test_ivf, df_test_di = df_ivf_di_split(df_test, is_train = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G6GyG-yMcn41","outputId":"2430d997-4fea-48ac-f8f9-650c220d1578","executionInfo":{"status":"ok","timestamp":1740470606558,"user_tz":-540,"elapsed":5498,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train data 수: 256351\n","test data 수: 90067\n","submission data 수: 90067\n","data 수: 256351\n","시술유형 IVF train data 수: 250060\n","시술유형 DI train data 수: 6291\n","data 수: 90067\n","시술유형 IVF test data 수: 87891\n","시술유형 DI test data 수: 2176\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVQIHe7WBL_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740470612522,"user_tz":-540,"elapsed":358,"user":{"displayName":"윤석진","userId":"14953914264612970479"}},"outputId":"f1c354b4-e9e2-4a31-ccac-0446df818acf"},"outputs":[{"output_type":"stream","name":"stdout","text":["시술 시기 코드: 7\n","시술 당시 나이: 7\n","임신 시도 또는 마지막 임신 경과 연수: 21\n","특정 시술 유형: 20\n","배란 자극 여부: 2\n","배란 유도 유형: 4\n","단일 배아 이식 여부: 2\n","착상 전 유전 검사 사용 여부: 1\n","착상 전 유전 진단 사용 여부: 2\n","남성 주 불임 원인: 2\n","남성 부 불임 원인: 2\n","여성 주 불임 원인: 2\n","여성 부 불임 원인: 2\n","부부 주 불임 원인: 2\n","부부 부 불임 원인: 2\n","불명확 불임 원인: 2\n","불임 원인 - 난관 질환: 2\n","불임 원인 - 남성 요인: 2\n","불임 원인 - 배란 장애: 2\n","불임 원인 - 여성 요인: 1\n","불임 원인 - 자궁경부 문제: 2\n","불임 원인 - 자궁내막증: 2\n","불임 원인 - 정자 농도: 2\n","불임 원인 - 정자 면역학적 요인: 2\n","불임 원인 - 정자 운동성: 2\n","불임 원인 - 정자 형태: 2\n","배아 생성 주요 이유: 13\n","총 시술 횟수: 7\n","클리닉 내 총 시술 횟수: 7\n","IVF 시술 횟수: 7\n","DI 시술 횟수: 7\n","총 임신 횟수: 7\n","IVF 임신 횟수: 7\n","DI 임신 횟수: 6\n","총 출산 횟수: 7\n","IVF 출산 횟수: 6\n","DI 출산 횟수: 5\n","총 생성 배아 수: 45\n","미세주입된 난자 수: 52\n","미세주입에서 생성된 배아 수: 41\n","이식된 배아 수: 4\n","미세주입 배아 이식 수: 4\n","저장된 배아 수: 42\n","미세주입 후 저장된 배아 수: 38\n","해동된 배아 수: 28\n","해동 난자 수: 31\n","수집된 신선 난자 수: 52\n","저장된 신선 난자 수: 41\n","혼합된 난자 수: 52\n","파트너 정자와 혼합된 난자 수: 52\n","기증자 정자와 혼합된 난자 수: 47\n","난자 출처: 2\n","정자 출처: 4\n","난자 기증자 나이: 5\n","정자 기증자 나이: 7\n","동결 배아 사용 여부: 2\n","신선 배아 사용 여부: 2\n","기증 배아 사용 여부: 2\n","대리모 여부: 2\n","PGD 시술 여부: 1\n","PGS 시술 여부: 1\n","난자 채취 경과일: 1\n","난자 해동 경과일: 2\n","난자 혼합 경과일: 8\n","배아 이식 경과일: 8\n","배아 해동 경과일: 8\n","임신 성공 여부: 2\n"]}],"source":["unique_counts = {column: df_train_ivf[column].nunique() for column in df_train_ivf.columns}\n","for column, count in unique_counts.items():\n","    print(f\"{column}: {count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcsFotf1LWvB","outputId":"c94e671d-bb66-484c-8546-02cefb3d5a4a","executionInfo":{"status":"ok","timestamp":1740470614793,"user_tz":-540,"elapsed":26,"user":{"displayName":"윤석진","userId":"14953914264612970479"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["시술 시기 코드: 7\n","시술 당시 나이: 6\n","임신 시도 또는 마지막 임신 경과 연수: 19\n","특정 시술 유형: 5\n","배란 자극 여부: 2\n","배란 유도 유형: 1\n","단일 배아 이식 여부: 0\n","착상 전 유전 검사 사용 여부: 0\n","착상 전 유전 진단 사용 여부: 0\n","남성 주 불임 원인: 2\n","남성 부 불임 원인: 2\n","여성 주 불임 원인: 2\n","여성 부 불임 원인: 2\n","부부 주 불임 원인: 2\n","부부 부 불임 원인: 2\n","불명확 불임 원인: 2\n","불임 원인 - 난관 질환: 2\n","불임 원인 - 남성 요인: 2\n","불임 원인 - 배란 장애: 2\n","불임 원인 - 여성 요인: 1\n","불임 원인 - 자궁경부 문제: 1\n","불임 원인 - 자궁내막증: 2\n","불임 원인 - 정자 농도: 2\n","불임 원인 - 정자 면역학적 요인: 1\n","불임 원인 - 정자 운동성: 1\n","불임 원인 - 정자 형태: 2\n","배아 생성 주요 이유: 0\n","총 시술 횟수: 7\n","클리닉 내 총 시술 횟수: 7\n","IVF 시술 횟수: 7\n","DI 시술 횟수: 7\n","총 임신 횟수: 6\n","IVF 임신 횟수: 4\n","DI 임신 횟수: 6\n","총 출산 횟수: 4\n","IVF 출산 횟수: 3\n","DI 출산 횟수: 4\n","총 생성 배아 수: 0\n","미세주입된 난자 수: 0\n","미세주입에서 생성된 배아 수: 0\n","이식된 배아 수: 0\n","미세주입 배아 이식 수: 0\n","저장된 배아 수: 0\n","미세주입 후 저장된 배아 수: 0\n","해동된 배아 수: 0\n","해동 난자 수: 0\n","수집된 신선 난자 수: 0\n","저장된 신선 난자 수: 0\n","혼합된 난자 수: 0\n","파트너 정자와 혼합된 난자 수: 0\n","기증자 정자와 혼합된 난자 수: 0\n","난자 출처: 1\n","정자 출처: 1\n","난자 기증자 나이: 1\n","정자 기증자 나이: 7\n","동결 배아 사용 여부: 0\n","신선 배아 사용 여부: 0\n","기증 배아 사용 여부: 0\n","대리모 여부: 0\n","PGD 시술 여부: 0\n","PGS 시술 여부: 0\n","난자 채취 경과일: 0\n","난자 해동 경과일: 0\n","난자 혼합 경과일: 0\n","배아 이식 경과일: 0\n","배아 해동 경과일: 0\n","임신 성공 여부: 2\n"]}],"source":["unique_counts = {column: df_train_di[column].nunique() for column in df_train_di.columns}\n","for column, count in unique_counts.items():\n","    print(f\"{column}: {count}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"_WwgWpWCIrim"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":0}