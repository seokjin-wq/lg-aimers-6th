{"cells":[{"cell_type":"markdown","metadata":{"id":"qu7nrq41QJiL"},"source":["### Import"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8701,"status":"ok","timestamp":1740565205577,"user":{"displayName":"윤석진","userId":"14953914264612970479"},"user_tz":-540},"id":"y3xv7hYGTi4A"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting category_encoders\n","  Downloading category_encoders-2.8.0-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: numpy\u003e=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n","Requirement already satisfied: pandas\u003e=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n","Requirement already satisfied: patsy\u003e=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n","Requirement already satisfied: scikit-learn\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n","Requirement already satisfied: scipy\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n","Requirement already satisfied: statsmodels\u003e=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.0.5-\u003ecategory_encoders) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.0.5-\u003ecategory_encoders) (2025.1)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.0.5-\u003ecategory_encoders) (2025.1)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn\u003e=1.6.0-\u003ecategory_encoders) (1.4.2)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn\u003e=1.6.0-\u003ecategory_encoders) (3.5.0)\n","Requirement already satisfied: packaging\u003e=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels\u003e=0.9.0-\u003ecategory_encoders) (24.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas\u003e=1.0.5-\u003ecategory_encoders) (1.17.0)\n","Downloading category_encoders-2.8.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: category_encoders\n","Successfully installed category_encoders-2.8.0\n","Collecting catboost\n","  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n","Requirement already satisfied: numpy\u003c2.0,\u003e=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas\u003e=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=0.24-\u003ecatboost) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=0.24-\u003ecatboost) (2025.1)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=0.24-\u003ecatboost) (2025.1)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib-\u003ecatboost) (1.3.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib-\u003ecatboost) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib-\u003ecatboost) (4.56.0)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib-\u003ecatboost) (1.4.8)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib-\u003ecatboost) (24.2)\n","Requirement already satisfied: pillow\u003e=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib-\u003ecatboost) (11.1.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib-\u003ecatboost) (3.2.1)\n","Requirement already satisfied: tenacity\u003e=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly-\u003ecatboost) (9.0.0)\n","Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: catboost\n","Successfully installed catboost-1.2.7\n"]}],"source":["!pip install category_encoders\n","!pip install catboost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ey8-1l_QJiO"},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import os\n","import json\n","import re\n","\n","from sklearn.linear_model import (\n","    LogisticRegression\n",")\n","\n","from sklearn.ensemble import (\n","    ExtraTreesClassifier,\n","    RandomForestClassifier\n",")\n","\n","from sklearn.metrics import (\n","    accuracy_score,\n","    confusion_matrix,\n","    f1_score,\n","    precision_score,\n","    recall_score,\n","    roc_auc_score\n",")\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","import category_encoders as ce\n","\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","from xgboost import XGBClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from scipy.stats import rankdata\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"markdown","metadata":{"id":"I5nWl4UXQJiP"},"source":["### Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1197,"status":"ok","timestamp":1740565210479,"user":{"displayName":"윤석진","userId":"14953914264612970479"},"user_tz":-540},"id":"Uoab0X_lQRua","outputId":"c3c7dffa-b213-4c86-ab8e-8dbd936d7df1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1740570140927,"user":{"displayName":"윤석진","userId":"14953914264612970479"},"user_tz":-540},"id":"8x1vnRQ8Qwkg","outputId":"dec5044b-f0bd-46e7-d9bd-bdce26cf4277"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","/content/drive/MyDrive/Aimers_6th/Data\n"]}],"source":["import os\n","\n","# 현재 작업 디렉터리 출력\n","print(os.getcwd())\n","\n","data_path = os.path.join(os.getcwd(), 'drive', 'MyDrive', 'Aimers_6th', 'Data')\n","print(data_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cljkaVMJCF58"},"outputs":[],"source":["config = {\n","    'root': data_path\n","    , 'train_path': f'{data_path}/train.csv'\n","    , 'test_path': f'{data_path}/test.csv'\n","    , 'submit_path': f'{data_path}/sample_submission.csv'\n","    , 'seed_list': [42]\n","    , 'k_fold': 5\n","    , 'model': 'lgb'       # cbt, logistic, et, rf, lgb, xgb\n","    , 'encoding': None # None(lgb, xgb, cbt), target, one-hot, ordinal, catboost\n","\n","}"]},{"cell_type":"markdown","metadata":{"id":"SKK9T6wdC7tq"},"source":["### HyperParameter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FM3otssjC-ur"},"outputs":[],"source":["# Our best parameters\n","params_di = {\n","    'logistic': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'max_iter': 300,\n","        'penalty': 'l2'\n","    },\n","\n","    'et': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        'max_samples': 0.5\n","\n","    },\n","\n","    'rf': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        # 'max_samples': 0.5,\n","        'bootstrap': False,\n","\n","    },\n","\n","    'lgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary',\n","        'n_jobs': 1,\n","        'verbosity': -1,\n","        'early_stopping_rounds': 10,\n","        'deterministic': True,\n","        'n_estimators': 910,\n","        'learning_rate': 0.2511885407801018,\n","        'num_leaves': 28,\n","        'max_depth': 4,\n","        'min_child_samples': 56,\n","        'subsample': 0.10122821600860445,\n","        'colsample_bytree': 0.6337550995282828,\n","        'reg_alpha': 0.40455183633441194,\n","        'reg_lambda': 0.000689949085617777,\n","\n","    },\n","\n","    'xgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'auc',\n","        'n_jobs': 1,\n","        'early_stopping_rounds': 10,\n","        'enable_categorical': True,\n","        'tree_method': 'hist',\n","\n","        'n_estimators': 441,\n","        'learning_rate': 0.03721359333248489,\n","        'max_depth': 4,\n","        'min_child_weight': 8.938182919719816,\n","        'subsample': 0.9671371022238382,\n","        'colsample_bytree': 0.5780876686670449,\n","        'gamma': 3.510090814742715e-06,\n","        'lambda': 1.0496048644425573,\n","        'alpha': 3.412427838959816e-05,\n","\n","\n","    },\n","\n","    # 'cbt': {\n","    #     'random_seed': config['seed_list'][0],\n","    #     'objective': 'Logloss',\n","    #     'eval_metric': 'AUC',\n","    #     'auto_class_weights': 'Balanced',\n","    #     'verbose': 100,\n","    #     'early_stopping_rounds': 10,\n","    #     'learning_rate': 0.1,\n","    #     'n_estimators': 300,\n","    #     'max_depth': 6,\n","    #     'l2_leaf_reg': 1,\n","    #     'min_data_in_leaf': 2,\n","    #     'subsample': 0.5,\n","    #     'task_type': 'CPU',\n","    #     'allow_writing_files': False\n","    # }\n","    'cbt': {\n","        'random_seed': config['seed_list'][0],\n","        'objective': 'Logloss',\n","        'eval_metric': 'AUC',\n","        'auto_class_weights': 'Balanced',\n","        'verbose': 100,\n","        'early_stopping_rounds': 10,\n","        'task_type': 'CPU',\n","        'allow_writing_files': False,\n","\n","        'learning_rate': 0.0051235964245759,\n","        'n_estimators': 288,\n","        'max_depth': 9,\n","        'l2_leaf_reg': 7.513168595258848,\n","        'bagging_temperature': 0.5106549389945279,\n","        'random_strength': 5.047046317652829,\n","        'border_count': 50,\n","        'min_data_in_leaf': 25,\n","        'subsample': 0.8799604706872908,\n","        'colsample_bylevel': 0.7386942588777181,\n","\n","    }\n","}\n","\n","params_ivf = {\n","    'logistic': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'max_iter': 300,\n","        'penalty': 'l2'\n","    },\n","\n","    'et': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        'max_samples': 0.5\n","\n","    },\n","\n","    'rf': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        # 'max_samples': 0.5,\n","        'bootstrap': False,\n","\n","    },\n","\n","    # 'lgb': {\n","    #     'random_state': config['seed_list'][0],\n","    #     'objective': 'binary',\n","    #     'n_jobs': 1,\n","    #     'verbosity': -1,\n","    #     'early_stopping_rounds': 10,\n","    #     'n_estimators': 300,\n","    #     'learning_rate': 0.1,\n","    #     'max_depth': 6,\n","    #     'reg_lambda': 1,\n","    #     'subsample': 0.5,\n","    #     'deterministic': True,\n","    # },\n","\n","    'lgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary',\n","        'n_jobs': 1,\n","        'verbosity': -1,\n","        'early_stopping_rounds': 10,\n","        'deterministic': True,\n","        'n_estimators': 399,\n","        'learning_rate': 0.08662393386614221,\n","        'num_leaves': 30,\n","        'max_depth': 7,\n","        'min_child_samples': 9,\n","        'subsample': 0.8712444912002683,\n","        'colsample_bytree': 0.7028171113108472,\n","        'reg_alpha': 3.2093670445847933e-05,\n","        'reg_lambda': 7.779128043413825,\n","\n","    },\n","\n","    'xgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'auc',\n","        'n_jobs': 1,\n","        'early_stopping_rounds': 10,\n","        'enable_categorical': True,\n","        'tree_method': 'hist',\n","\n","        'n_estimators': 237,\n","        'learning_rate': 0.04776299195908614,\n","        'max_depth': 6,\n","        'min_child_weight': 7.627814434191197,\n","        'subsample': 0.9134763046750406,\n","        'colsample_bytree': 0.43858126559157823,\n","        'gamma': 0.013695989699885162,\n","        'lambda': 0.08441956749102139,\n","        'alpha': 0.04219273458844118\n","    },\n","\n","\n","    # 'cbt': {\n","    #     'random_seed': config['seed_list'][0],\n","    #     'objective': 'Logloss',\n","    #     'eval_metric': 'AUC',\n","    #     'auto_class_weights': 'Balanced',\n","    #     'verbose': 100,\n","    #     'early_stopping_rounds': 10,\n","    #     'learning_rate': 0.1,\n","    #     'n_estimators': 300,\n","    #     'max_depth': 6,\n","    #     'l2_leaf_reg': 1,\n","    #     'min_data_in_leaf': 2,\n","    #     'subsample': 0.5,\n","    #     'task_type': 'CPU',\n","    #     'allow_writing_files': False\n","    # }\n","\n","    'cbt': {\n","        'random_seed': config['seed_list'][0],\n","        'objective': 'Logloss',\n","        'eval_metric': 'AUC',\n","        'auto_class_weights': 'Balanced',\n","        'verbose': 100,\n","        'early_stopping_rounds': 10,\n","        'task_type': 'CPU',\n","        'allow_writing_files': False,\n","\n","        'learning_rate': 0.06420870340097037,\n","        'n_estimators': 704,\n","        'max_depth': 7,\n","        'l2_leaf_reg': 5.428570600396231,\n","        'bagging_temperature': 0.9964805026288809,\n","        'random_strength': 1.4950577092436823,\n","        'border_count': 109,\n","        'min_data_in_leaf': 77,\n","        'subsample': 0.42364067415772133,\n","        'colsample_bylevel': 0.5429603138618737,\n","    }\n","}"]},{"cell_type":"markdown","metadata":{"id":"gwV9ZY6PDFoi"},"source":["### Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0D-Kj4MNDKIC"},"outputs":[],"source":["def set_seed(seed: int): # seed 고정 함수\n","    # Set the seed for reproducibility.\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","\n","\n","def read_data(config):\n","    # Load training, testing, and submission CSV files\n","    df_train = pd.read_csv(config['train_path']).drop(columns=['ID'])  # train data\n","    df_test = pd.read_csv(config['test_path']).drop(columns=['ID'])    # test data\n","    df_sub = pd.read_csv(config['submit_path'])\n","\n","    print(f'train data 수: {df_train.shape[0]}')\n","    print(f'test data 수: {df_test.shape[0]}')\n","    print(f'submission data 수: {df_sub.shape[0]}')\n","    return df_train, df_test, df_sub\n","\n","def df_ivf_di_split(df, is_train=False):\n","\n","    data_type = 'train' if is_train else 'test'\n","\n","    print(f'data 수: {df.shape[0]}')\n","\n","    df_ivf = df[df['시술 유형'] == 'IVF'].drop(columns=['시술 유형'])\n","    df_di = df[df['시술 유형'] == 'DI'].drop(columns=['시술 유형'])\n","\n","    print(f'시술유형 IVF {data_type} data 수: {df_ivf.shape[0]}')\n","    print(f'시술유형 DI {data_type} data 수: {df_di.shape[0]}')\n","\n","    return df_ivf, df_di\n","\n","\n","def get_clf_eval(y_test, y_proba=None, fold_no=None):\n","    # Calculate and print evaluation metrics and confusion matrix,\n","    # accuracy, precision, recall, f1 and roc_auc score.\n","    # Optionally includes fold number in the output.\n","\n","    # 임계값 0.5 기준 예측값 생성\n","    y_pred = (y_proba \u003e= 0.5).astype(int)\n","\n","    y_test = y_test.values\n","\n","    confusion = confusion_matrix(y_test, y_pred)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    roc_auc = roc_auc_score(y_test, y_proba)  # ROC-AUC는 확률값 그대로 사용\n","\n","    fold_info = f'Fold #{fold_no}' if fold_no is not None else ''\n","    print(f'{fold_info} ACC: {accuracy:.4f}, PRE: {precision:.4f}, REC: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}')\n","    return roc_auc\n","\n","\n","# Categorical variable encoding method.\n","def category_encoding(df_train, df_test, base_num_features, base_cat_features, config, is_ivf=False):\n","    target = '임신 성공 여부'\n","\n","    data_name = 'IVF' if is_ivf else 'DI'\n","\n","    new_df_train = pd.concat([df_train[base_num_features].copy(), df_train[target]], axis = 1)\n","    new_df_test = df_test[base_num_features].copy()\n","\n","    print(f'{data_name} category 변수 인코딩: {config[\"encoding\"]}')\n","\n","    if config['encoding'] == 'target':\n","        encoder = ce.TargetEncoder(cols=base_cat_features)\n","\n","    elif config['encoding'] == 'ordinal':\n","        encoder = ce.OrdinalEncoder(cols=base_cat_features)\n","\n","    elif config['encoding'] == 'catboost':\n","        encoder = ce.CatBoostEncoder(cols=base_cat_features)#, random_state=config['seed'])\n","\n","    if config['encoding'] in ['target', 'ordinal', 'catboost']:\n","        encoder.fit(df_train[base_cat_features], df_train[target])\n","        new_df_train[base_cat_features] = encoder.transform(df_train[base_cat_features])\n","        new_df_test[base_cat_features] = encoder.transform(df_test[base_cat_features])\n","\n","    elif config['encoding'] == 'one-hot':\n","        encoder = ce.OneHotEncoder(cols=base_cat_features, use_cat_names = True)\n","        encoder.fit(df_train[base_cat_features], df_train[target])\n","        result_tr = encoder.transform(df_train[base_cat_features])\n","        result_te = encoder.transform(df_test[base_cat_features])\n","\n","        result_tr.columns = result_tr.columns.str.replace(r'[^ㄱ-ㅎ가-힣A-Za-z0-9_]', '_', regex=True)\n","        result_te.columns = result_te.columns.str.replace(r'[^ㄱ-ㅎ가-힣A-Za-z0-9_]', '_', regex=True)\n","\n","        new_df_train = pd.concat([new_df_train, result_tr], axis = 1)\n","        new_df_test = pd.concat([new_df_test, result_te], axis = 1)\n","\n","    elif config['encoding'] is None:\n","        new_df_train = pd.concat([new_df_train, df_train[base_cat_features]], axis = 1)\n","        new_df_test = pd.concat([new_df_test, df_test[base_cat_features]], axis = 1)\n","\n","    _, base_cat_features, base_features = make_feature_lists(new_df_train, is_ivf=is_ivf)\n","\n","    return new_df_train, new_df_test, base_cat_features, base_features\n","\n","def feature_engineering(df_input, tr_removed_column_list, is_train=False, is_ivf=False):\n","    df = df_input.copy()\n","\n","    data_name = 'IVF' if is_ivf else 'DI'\n","    data_type = 'train' if is_train else 'test'\n","\n","    if is_train:\n","        removed_column_list = []\n","    else:\n","        removed_column_list = tr_removed_column_list\n","\n","\n","    print(f'중복 제거 전 {data_type} {data_name} data 수: {df.shape[0]}')\n","\n","    # drop_duplicates\n","    df = df.drop_duplicates(keep='first')\n","\n","    print(f'중복 제거 후 {data_type} {data_name} data 수: {df.shape[0]}')\n","\n","    # 횟수 관련 column\n","    count_columns = [column for column in df.columns if '횟수' in column]\n","\n","    for col in count_columns:\n","        df[col] = df[col].str.replace('회', '').str.replace('이상', '').str.replace(' ', '').astype(int)\n","\n","\n","    # 시술 당시 나이 범위를 중앙값으로 변환하는 매핑 딕셔너리 (누락된 범위 추가)\n","    treatment_age = {\n","        \"만18-34세\": 26,\n","        \"만35-37세\": 36,\n","        \"만38-39세\": 38.5,\n","        \"만40-42세\": 41,\n","        \"만43-44세\": 43.5,\n","        \"만45-50세\": 47.5,\n","        \"알 수 없음\": -1  # 알 수 없음은 -1로 처리\n","    }\n","\n","    # 공백 제거 후 매핑\n","    # 시술 당시 나이 숫자 mapping -\u003e DI에만 적용\n","    if is_ivf:\n","        df[\"시술 당시 나이\"] = df[\"시술 당시 나이\"].str.strip().map(treatment_age).astype(float)\n","\n","    # # 정자 난자기증자 나이 범위를 중앙값으로 변환하는 매핑 딕셔너리 (누락된 범위 추가)\n","    donor_age = {\n","        \"만20세 이하\": 20,\n","        \"만21-25세\": 23,\n","        \"만26-30세\": 28,\n","        \"만31-35세\": 33,\n","        \"만36-40세\": 38,\n","        \"만41-45세\": 43,\n","        \"알 수 없음\": -1 # 알 수 없음은 -1로 처리\n","    }\n","\n","    # 공백 제거 후 매핑\n","    if is_ivf:\n","        df[\"난자 기증자 나이\"] = df[\"난자 기증자 나이\"].str.strip().map(donor_age).astype(float)\n","\n","    df[\"정자 기증자 나이\"] = df[\"정자 기증자 나이\"].str.strip().map(donor_age).astype(float)\n","\n","    # 특정 시술 유형\n","    treat_types = []\n","    # embryo_creation_reasons = []\n","\n","    if not is_ivf:\n","        treat_types.extend(['IUI', 'ICI', 'Generic DI', 'IVI'])\n","\n","    if is_ivf:\n","        treat_types.extend(['ICSI', 'IVF', 'BLASTOCYST', 'AH', 'Unknown'])\n","        # embryo_creation_reasons.extend(['현재 시술용', '배아 저장용', '기증용', '난자 저장용'])\n","\n","    # 각 target에 대한 Multi-Hot Encoding 및 Count 계산\n","    for treat_type in treat_types:\n","        # 각 행에서 target이 등장하는 횟수 계산\n","        df[treat_type] = df['특정 시술 유형'].str.count(treat_type)\n","\n","    # if is_ivf:\n","    #     for embryo_creation_reason in embryo_creation_reasons:\n","    #         # 각 행에서 target이 등장하는 횟수 계산\n","    #         df[embryo_creation_reason] = df['배아 생성 주요 이유'].str.count(embryo_creation_reason)\n","\n","    df_column_list = df.columns\n","    print(f'column 제거 전 {data_type} {data_name} data shape: {df.shape}')\n","\n","    if is_train:\n","        # train data에서 전부 결측치거나 값 1개만 갖는 column 제거\n","\n","        for feat in df_column_list:\n","\n","            null_count = df[feat].isna().sum() # feat 열 결측치 수\n","\n","            if df[feat].nunique() == 0 or (df[feat].nunique() == 1 and null_count == 0):\n","                df = df.drop(columns=[feat])\n","                removed_column_list.append(feat)\n","\n","\n","    # # test data에서는 train data에서 제거된 column 제거\n","    else:\n","\n","        df = df.drop(columns=removed_column_list)\n","\n","    print(f'column 제거 후 {data_type} {data_name} data shape: {df.shape}')\n","\n","    # 파생변수 생성\n","    # IVF에만 존재하는 피처\n","    if is_ivf:\n","        # 비율 및 비율 차이\n","        df[\"배아_생성률\"] = df[\"미세주입에서 생성된 배아 수\"] / (df[\"미세주입된 난자 수\"] + 1e-5)\n","        df[\"배아_이식률\"] = df[\"이식된 배아 수\"] / (df[\"총 생성 배아 수\"] + 1e-5)\n","        df[\"미세주입_이식률\"] = df[\"미세주입 배아 이식 수\"] / (df[\"미세주입에서 생성된 배아 수\"] + 1e-5)\n","        df[\"배아_저장률\"] = df[\"저장된 배아 수\"] / (df[\"총 생성 배아 수\"] + 1e-5)\n","        df[\"배아_해동률\"] = df[\"해동된 배아 수\"] / (df[\"저장된 배아 수\"] + 1e-5)\n","        df[\"기증자_정자_비율\"] = df[\"기증자 정자와 혼합된 난자 수\"] / (df[\"혼합된 난자 수\"] + 1e-5)\n","        df[\"배아_손실률\"] = 1 - (df[\"미세주입에서 생성된 배아 수\"] / (df[\"미세주입된 난자 수\"] + 1e-5))\n","        df[\"배아_이식_대비_해동된_배아_비율\"] = df[\"해동된 배아 수\"] / (df[\"이식된 배아 수\"] + 1e-5)\n","        df[\"미세주입_비율\"] = df[\"미세주입된 난자 수\"] / (df[\"총 생성 배아 수\"] + 1e-5)\n","        df[\"신선_난자_저장률\"] = df[\"저장된 신선 난자 수\"] / (df[\"수집된 신선 난자 수\"] + 1e-5)\n","        df[\"정자_혼합_비율_차이\"] = (\n","            df[\"파트너 정자와 혼합된 난자 수\"] / (df[\"혼합된 난자 수\"] + 1e-5)\n","            - df[\"기증자 정자와 혼합된 난자 수\"] / (df[\"혼합된 난자 수\"] + 1e-5)\n","        )\n","\n","        # 차이 및 변화량\n","        df[\"미세주입_실패_수\"] = df[\"미세주입된 난자 수\"] - df[\"미세주입에서 생성된 배아 수\"]\n","        df[\"이식되지_않은_배아_수\"] = df[\"미세주입에서 생성된 배아 수\"] - df[\"미세주입 배아 이식 수\"]\n","        df[\"저장되지_않은_신선_난자_수\"] = df[\"수집된 신선 난자 수\"] - df[\"저장된 신선 난자 수\"]\n","        df[\"기증자_혼합_난자_수\"] = df[\"혼합된 난자 수\"] - df[\"파트너 정자와 혼합된 난자 수\"]\n","        df[\"해동_후_이식_까지_시간\"] = df[\"배아 이식 경과일\"] - df[\"배아 해동 경과일\"]\n","        df[\"해동_후_미세주입_성공률\"] = df[\"미세주입된 난자 수\"] / (df[\"해동된 배아 수\"] + 1e-5)\n","        # df[\"배아_생성_감소량\"] = df[\"미세주입된 난자 수\"] - df[\"미세주입에서 생성된 배아 수\"]\n","        # df[\"배아_해동_후_남은_기간\"] = df[\"배아 이식 경과일\"] - df[\"배아 해동 경과일\"]\n","        df[\"배아_저장_후_해동_기간\"] = df[\"배아 해동 경과일\"] - df[\"난자 혼합 경과일\"]\n","        df[\"정자_혼합_후_배아_생성_경과일\"] = df[\"배아 이식 경과일\"] - df[\"난자 혼합 경과일\"]\n","        # df[\"미세주입_대비_해동된_배아_비율\"] = df[\"미세주입된 난자 수\"] / (df[\"해동된 배아 수\"] + 1e-5)\n","\n","    # 불임 원인 multi hot -\u003e 하나의 feature\n","\n","    # infertility_columns = [column for column in df.columns if '불임 원인' in column]\n","\n","    # # dot()을 사용하여 1이 있는 컬럼을 결합 (각 feature 사이에 공백 추가)\n","    # df['불임 원인 종합'] = df[infertility_columns].dot(pd.Index([f'{col.replace(\"불임 원인\", \"\").replace(\" \", \"\")} ' for col in infertility_columns])).str.strip()\n","\n","    # # 한글만 남기고 나머지 문자 제거 (정규 표현식 사용)\n","    # df['불임 원인 종합'] = df['불임 원인 종합'].apply(lambda x: re.sub(r'[^가-힣 ]', '', x))\n","\n","    # # split()과 join()을 사용하여 공백을 ','로 변경\n","    # df['불임 원인 종합'] = df['불임 원인 종합'].apply(lambda x: ', '.join(x.split()))\n","\n","    # df = df.drop(columns=infertility_columns)\n","\n","    return df, removed_column_list\n","\n","def make_feature_lists(df, is_ivf=False):\n","    base_features = []     # all features except target variable.\n","    base_num_features = [] # numerical features\n","    base_cat_features = [] # categorical features\n","\n","    data_name = 'IVF' if is_ivf else 'DI'\n","\n","    for feat in df.columns:\n","        # skip the target\n","        if feat == '임신 성공 여부':\n","            continue\n","\n","        base_features.append(feat)\n","\n","        if df[feat].dtype in ['object', 'category']:\n","            base_cat_features.append(feat)\n","        else:\n","            base_num_features.append(feat)\n","\n","    # infertility_columns = [column for column in df.columns if '불임 원인' in column]\n","\n","    # 공통 제거 변수\n","    removal_features = {\n","            'ID', '불임 원인 - 여성 요인', '불임 원인 - 정자 면역학적 요인', '불임 원인 - 자궁경부 문제',\n","            '시술 유형', '배란 유도 유형', '특정 시술 유형','배란 자극 여부','부부 주 불임 원인','여성 주 불임 원인'}\n","\n","    # ivf 제거 변수\n","    removal_features_ivf = {\n","        '남성 주 불임 원인', '남성 부 불임 원인','부부 부 불임 원인','AH','신선_난자 저장률','IVF',\n","        '저장된 신선 난자 수', '신선 배아 사용 여부', '대리모 여부','난자 해동 경과일','DI 임신 횟수','불임 원인 - 정자 농도',\n","        '동결 배아 사용 여부','배아_저장_후_해동_기간','불임 원인 - 정자 운동성','DI 출산 횟수',\n","        '불임 원인 - 정자 형태', '기증 배아 사용 여부','배아 해동 경과일'\n","    }\n","\n","    # di 제거 변수\n","    removal_features_di = {\n","        '불임 원인- 배란 장애','불명확 불임 원인',' 임신 시도 또는 마지막 임신 경과 연수','총 출산 횟수',\n","        '총 임신 횟수','시술 시기 코드'\n","    }\n","    if is_ivf:\n","        removal_features = removal_features.union(removal_features_ivf)\n","    else:\n","        removal_features = removal_features.union(removal_features_di)\n","\n","    # removal_features.update(infertility_columns)\n","\n","    # remove the specified features\n","    base_num_features = [i for i in base_num_features if i not in removal_features]\n","    base_cat_features = [i for i in base_cat_features if i not in removal_features]\n","    base_features = [i for i in base_features if i not in removal_features]\n","\n","    print(f'{data_name} numeric feature 수: {len(base_num_features)}')\n","    print(f'{data_name} category feature 수: {len(base_cat_features)}')\n","    print(f'{data_name} 전체 feature 수: {len(base_features)}')\n","\n","    return base_num_features, base_cat_features, base_features\n","\n","def filling_missing_values(df_input, base_cat_features, base_num_features, config):\n","    df = df_input.copy()\n","\n","    # Fill missing values for categorical features with 'Unknown' and ensure their data type is string.\n","    for base_cat_feat in base_cat_features:\n","        df[base_cat_feat] = df[base_cat_feat].astype(str)\n","        df[base_cat_feat] = df[base_cat_feat].fillna('알 수 없음')\n","\n","        if config['encoding'] is None:\n","            df[base_cat_feat] = df[base_cat_feat].astype('category')\n","\n","\n","    # Fill missing values for numerical features with -1.\n","    for base_num_feat in base_num_features:\n","        df[base_num_feat] = df[base_num_feat].fillna(-1)\n","\n","    return df\n","\n","\n","def model_kfold(df, config, params, base_features, base_cat_features, is_ivf=False):\n","    target = '임신 성공 여부'\n","\n","    data_name = 'IVF' if is_ivf else 'DI'\n","\n","    skf = StratifiedKFold(n_splits=config['k_fold'], shuffle=True, random_state=config['seed'])\n","    models = []       # trained models\n","    roc_auc_scores = []  # roc_auc_scores for validation sets\n","\n","    model_params = params[config['model']]\n","\n","    for k_fold, (train_idx, valid_idx) in enumerate(skf.split(df[base_features], df[target])):\n","        print(f'Fold #{k_fold + 1}')\n","        X_train, y_train = df[base_features].iloc[train_idx], df[target].iloc[train_idx]\n","        X_valid, y_valid = df[base_features].iloc[valid_idx], df[target].iloc[valid_idx]\n","\n","        if config['model'] == 'logistic':\n","            model = LogisticRegression(**model_params)\n","\n","        elif config['model'] == 'et':\n","            model = ExtraTreesClassifier(**model_params)\n","\n","        elif config['model'] == 'rf':\n","            model = RandomForestClassifier(**model_params)\n","\n","        if config['model'] in ['logistic', 'et', 'rf']:\n","            model.fit(X_train, y_train)\n","\n","        elif config['model'] == 'lgb':\n","            model = LGBMClassifier(**model_params)\n","\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                eval_metric='auc',\n","                categorical_feature=base_cat_features, # specify categorical features\n","            )\n","\n","        elif config['model'] == 'xgb':\n","            model = XGBClassifier(**model_params)\n","\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                verbose = 100\n","            )\n","\n","        elif config['model'] == 'cbt':\n","            model = CatBoostClassifier(**model_params)\n","\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                cat_features=base_cat_features, # specify categorical features\n","            )\n","\n","        # save the trained model\n","        models.append(model)\n","\n","        # evaluate the model\n","        # --- train-set\n","        print(f'[{data_name} Train] ', end='')\n","        y_prob = model.predict_proba(X_train)[:, 1]\n","        _ = get_clf_eval(y_train, y_prob, k_fold + 1)\n","\n","        # --- valid-set\n","        print(f'[{data_name} Valid] ', end='')\n","        y_prob = model.predict_proba(X_valid)[:, 1]\n","        roc_auc_score = get_clf_eval(y_valid, y_prob, k_fold + 1)\n","\n","        roc_auc_scores.append(roc_auc_score)\n","\n","    avg_roc_auc = np.mean(roc_auc_scores)\n","    var_roc_auc = np.var(roc_auc_scores)\n","\n","    print(f'Avg. roc-auc of validset {data_name}: {avg_roc_auc}')\n","    print(f'Var. roc-auc of validset {data_name}: {var_roc_auc}')\n","\n","    return models, avg_roc_auc, var_roc_auc\n","\n","def kfold_submission(df_test_ivf, df_test_di, df_sub, models_ivf, models_di, config):\n","    feat_importance_path = f\"{config['root']}/FeatureImportance\"\n","    submission_path = f\"{config['root']}/Submission\"\n","    json_path = f\"{config['root']}/Json\"\n","\n","    if not os.path.exists(feat_importance_path):\n","        os.makedirs(feat_importance_path)\n","\n","    if not os.path.exists(submission_path):\n","        os.makedirs(submission_path)\n","\n","    if not os.path.exists(json_path):\n","        os.makedirs(json_path)\n","\n","    # get current date and time\n","    now = datetime.now()\n","\n","    # record the year, month, day, hour, and minute for naming files.\n","    year = now.year\n","    month = now.month\n","    day = now.day\n","    hour = now.hour\n","    minute = now.minute\n","\n","    # file format\n","    submission_time = f\"{year:04d}{month:02d}{day:02d}_{hour:02d}{minute:02d}\"[2:]\n","    target = 'probability'\n","\n","    # apply feature engineering\n","    base_num_features_ivf, base_cat_features_ivf, base_features_ivf = make_feature_lists(df_test_ivf, is_ivf=True)\n","    df_test_ivf = filling_missing_values(df_test_ivf, base_cat_features_ivf, base_num_features_ivf, config)\n","    X_test_ivf = df_test_ivf[base_features_ivf]\n","\n","    base_num_features_di, base_cat_features_di, base_features_di = make_feature_lists(df_test_di, is_ivf=False)\n","    df_test_di = filling_missing_values(df_test_di, base_cat_features_di, base_num_features_di, config)\n","    X_test_di = df_test_di[base_features_di]\n","\n","    # dataframe for feature importances\n","    base_features = list(set(base_features_ivf).union(set(base_features_di)))\n","\n","    df_feature_importance_all_ivf = pd.DataFrame({'features': base_features_ivf})\n","    df_feature_importance_all_di = pd.DataFrame({'features': base_features_di})\n","\n","def rank_ensemble(predictions_list):\n","    \"\"\"\n","    여러 모델의 예측값을 받아서 Rank Ensemble을 적용한 최종 예측값을 반환하는 함수\n","    \"\"\"\n","    num_models = len(predictions_list)\n","    num_samples = len(predictions_list[0])\n","\n","    rank_preds = np.zeros((num_samples, num_models))\n","\n","    # 각 모델의 예측값을 랭크 변환\n","    for i, preds in enumerate(predictions_list):\n","        rank_preds[:, i] = rankdata(preds) / num_samples  # 0~1 범위로 정규화된 순위\n","\n","    # 모든 모델의 Rank 평균\n","    final_rank_preds = rank_preds.mean(axis=1)\n","\n","    return final_rank_preds\n","\n","    ivf_preds_list = []\n","    di_preds_list = []\n","\n","    for i, model_ivf in enumerate(models_ivf):\n","      preds_ivf = model_ivf.predict_proba(X_test_ivf)[:, 1]\n","      ivf_preds_list.append(preds_ivf)\n","\n","\n","      # save feature importance of current model\n","      if config['model'] in ['logistic']:\n","        df_feature_importance_all_ivf[f'model_{i}'] = model_ivf.coef_.squeeze()\n","\n","      elif config['model'] in ['et', 'rf', 'lgb', 'xgb']:\n","        df_feature_importance_all_ivf[f'model_{i}'] = model_ivf.feature_importances_\n","\n","      elif config['model'] == 'cbt':\n","        df_feature_importance_all_ivf[f'model_{i}'] = model_ivf.get_feature_importance()\n","\n","    for i, model_di in enumerate(models_di):\n","      preds_di = model_di.predict_proba(X_test_di)[:, 1]\n","      di_preds_list.append(preds_di)\n","\n","    # save feature importance of current model\n","      if config['model'] in ['logistic']:\n","        df_feature_importance_all_di[f'model_{i}'] = model_di.coef_.squeeze()\n","\n","      elif config['model'] in ['et', 'rf', 'lgb', 'xgb']:\n","        df_feature_importance_all_di[f'model_{i}'] = model_di.feature_importances_\n","\n","      elif config['model'] == 'cbt':\n","        df_feature_importance_all_di[f'model_{i}'] = model_di.get_feature_importance()\n","\n","    # Rank Ensemble 적용\n","    y_probs_ivf = rank_ensemble(ivf_preds_list)\n","    y_probs_di = rank_ensemble(di_preds_list)\n","\n","    # 최종 예측값 저장\n","    df_sub.loc[df_test_ivf.index, target] = y_probs_ivf\n","    df_sub.loc[df_test_di.index, target] = y_probs_di\n","\n","    # save submission file as CSV\n","    df_sub.to_csv(f\"{submission_path}/{submission_time}_{config['model']}_{config['encoding']}_submission.csv\", index=False)\n","\n","    # compute avarege, rank\n","    df_feature_importance_all_ivf['average'] = df_feature_importance_all_ivf.iloc[:, 1:].mean(axis=1).values\n","    df_feature_importance_all_ivf['rank'] = df_feature_importance_all_ivf['average'].rank(ascending=False)\n","    df_feature_importance_all_ivf = df_feature_importance_all_ivf.sort_values(by='rank')\n","\n","    df_feature_importance_all_di['average'] = df_feature_importance_all_di.iloc[:, 1:].mean(axis=1).values\n","    df_feature_importance_all_di['rank'] = df_feature_importance_all_di['average'].rank(ascending=False)\n","    df_feature_importance_all_di = df_feature_importance_all_di.sort_values(by='rank')\n","\n","    # save the feature importance as CSV\n","    df_feature_importance_all_ivf.to_csv(f'{feat_importance_path}/feat_import_{submission_time}_{config[\"model\"]}_IVF_{config[\"encoding\"]}.csv', index=False)\n","    df_feature_importance_all_di.to_csv(f'{feat_importance_path}/feat_import_{submission_time}_{config[\"model\"]}_DI_{config[\"encoding\"]}.csv', index=False)\n","\n","    # save parameters as JSON\n","    json_data = json.dumps(config, indent=4)\n","\n","    with open(f'{json_path}/{submission_time}_{config[\"model\"]}_{config[\"encoding\"]}.json', 'w') as file:\n","        file.write(json_data)"]},{"cell_type":"markdown","metadata":{"id":"3d4zUcXXQJiQ"},"source":["### Data Pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7wSJYvkYESQv"},"outputs":[],"source":["def main(config, params_di, params_ivf):\n","    models_ivf = []\n","    models_di = []\n","\n","    for seed in config['seed_list']:\n","        config['seed'] = seed\n","        params_di['random_seed'] = seed\n","        params_ivf['random_seed'] = seed\n","\n","        # set seed\n","        set_seed(config['seed'])\n","\n","        # read data set\n","        df_train, df_test, df_sub = read_data(config)\n","\n","        # ivf di split\n","        df_train_ivf, df_train_di = df_ivf_di_split(df_train, is_train = True)\n","        df_test_ivf, df_test_di = df_ivf_di_split(df_test, is_train = False)\n","\n","        # feature engineering (train,test)\n","        df_train_ivf, removed_column_list_ivf = feature_engineering(df_train_ivf, None, is_train=True, is_ivf=True)\n","        df_test_ivf, _ = feature_engineering(df_test_ivf, removed_column_list_ivf, is_train=False, is_ivf=True)\n","\n","        df_train_di, removed_column_list_di = feature_engineering(df_train_di, None, is_train=True, is_ivf=False)\n","        df_test_di, _ = feature_engineering(df_test_di, removed_column_list_di, is_train=False, is_ivf=False)\n","\n","        # feature list 생성 (train)\n","        base_num_features_ivf, base_cat_features_ivf, base_features_ivf = make_feature_lists(df_train_ivf, is_ivf=True)\n","        base_num_features_di, base_cat_features_di, base_features_di = make_feature_lists(df_train_di, is_ivf=False)\n","\n","        # 결측치 처리\n","        df_train_ivf = filling_missing_values(df_train_ivf, base_cat_features_ivf, base_num_features_ivf, config)\n","        df_train_di = filling_missing_values(df_train_di, base_cat_features_di, base_num_features_di, config)\n","\n","        # encoding\n","        df_train_ivf, df_test_ivf, base_cat_features_ivf, base_features_ivf = category_encoding(df_train_ivf, df_test_ivf, base_num_features_ivf, base_cat_features_ivf, config, is_ivf=True)\n","        df_train_di, df_test_di, base_cat_features_di, base_features_di = category_encoding(df_train_di, df_test_di, base_num_features_di, base_cat_features_di, config, is_ivf=False)\n","\n","        # check model performance\n","        model_ivf, avg_roc_auc_ivf, var_roc_auc_ivf = model_kfold(df_train_ivf, config, params_ivf, base_features_ivf, base_cat_features_ivf, is_ivf=True)\n","        model_di, avg_roc_auc_di, var_roc_auc_di = model_kfold(df_train_di, config, params_di, base_features_di, base_cat_features_di, is_ivf=False)\n","\n","        config['avg_roc_auc_ivf'] = avg_roc_auc_ivf\n","        config['var_roc_auc_ivf'] = var_roc_auc_ivf\n","\n","        config['avg_roc_auc_di'] = avg_roc_auc_di\n","        config['var_roc_auc_di'] = var_roc_auc_di\n","\n","        models_ivf.extend(model_ivf)\n","        models_di.extend(model_di)\n","\n","    config['model_param_di'] = params_di[config['model']]\n","    config['model_param_ivf'] = params_ivf[config['model']]\n","\n","    # submissionㅊ\n","    kfold_submission(df_test_ivf, df_test_di, df_sub, models_ivf, models_di, config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66649,"status":"ok","timestamp":1740570341607,"user":{"displayName":"윤석진","userId":"14953914264612970479"},"user_tz":-540},"id":"NaZgJXIyEVDj","outputId":"6a2496ac-69aa-4a44-89fa-ebcafe34bdd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["train data 수: 256351\n","test data 수: 90067\n","submission data 수: 90067\n","data 수: 256351\n","시술유형 IVF train data 수: 250060\n","시술유형 DI train data 수: 6291\n","data 수: 90067\n","시술유형 IVF test data 수: 87891\n","시술유형 DI test data 수: 2176\n","중복 제거 전 train IVF data 수: 250060\n","중복 제거 후 train IVF data 수: 250060\n","column 제거 전 train IVF data shape: (250060, 72)\n","column 제거 후 train IVF data shape: (250060, 71)\n","중복 제거 전 test IVF data 수: 87891\n","중복 제거 후 test IVF data 수: 87891\n","column 제거 전 test IVF data shape: (87891, 71)\n","column 제거 후 test IVF data shape: (87891, 70)\n","중복 제거 전 train DI data 수: 6291\n","중복 제거 후 train DI data 수: 6291\n","column 제거 전 train DI data shape: (6291, 71)\n","column 제거 후 train DI data shape: (6291, 34)\n","중복 제거 전 test DI data 수: 2176\n","중복 제거 후 test DI data 수: 2176\n","column 제거 전 test DI data shape: (2176, 70)\n","column 제거 후 test DI data shape: (2176, 33)\n","IVF numeric feature 수: 60\n","IVF category feature 수: 4\n","IVF 전체 feature 수: 64\n","DI numeric feature 수: 24\n","DI category feature 수: 1\n","DI 전체 feature 수: 25\n","IVF category 변수 인코딩: None\n","IVF numeric feature 수: 60\n","IVF category feature 수: 4\n","IVF 전체 feature 수: 64\n","DI category 변수 인코딩: None\n","DI numeric feature 수: 24\n","DI category feature 수: 1\n","DI 전체 feature 수: 25\n","Fold #1\n","[IVF Train] Fold #1 ACC: 0.7477, PRE: 0.5832, REC: 0.1240, F1: 0.2046, ROC-AUC: 0.7498\n","[IVF Valid] Fold #1 ACC: 0.7440, PRE: 0.5516, REC: 0.1151, F1: 0.1905, ROC-AUC: 0.7365\n","Fold #2\n","[IVF Train] Fold #2 ACC: 0.7473, PRE: 0.5826, REC: 0.1207, F1: 0.2000, ROC-AUC: 0.7472\n","[IVF Valid] Fold #2 ACC: 0.7433, PRE: 0.5469, REC: 0.1101, F1: 0.1833, ROC-AUC: 0.7397\n","Fold #3\n","[IVF Train] Fold #3 ACC: 0.7479, PRE: 0.5845, REC: 0.1258, F1: 0.2070, ROC-AUC: 0.7493\n","[IVF Valid] Fold #3 ACC: 0.7441, PRE: 0.5501, REC: 0.1191, F1: 0.1958, ROC-AUC: 0.7386\n","Fold #4\n","[IVF Train] Fold #4 ACC: 0.7469, PRE: 0.5809, REC: 0.1167, F1: 0.1944, ROC-AUC: 0.7468\n","[IVF Valid] Fold #4 ACC: 0.7426, PRE: 0.5404, REC: 0.1079, F1: 0.1799, ROC-AUC: 0.7379\n","Fold #5\n","[IVF Train] Fold #5 ACC: 0.7477, PRE: 0.5830, REC: 0.1244, F1: 0.2050, ROC-AUC: 0.7482\n","[IVF Valid] Fold #5 ACC: 0.7428, PRE: 0.5397, REC: 0.1143, F1: 0.1887, ROC-AUC: 0.7364\n","Avg. roc-auc of validset IVF: 0.7378369982025534\n","Var. roc-auc of validset IVF: 1.6250672955338323e-06\n","Fold #1\n","[DI Train] Fold #1 ACC: 0.8712, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.7296\n","[DI Valid] Fold #1 ACC: 0.8705, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.6478\n","Fold #2\n","[DI Train] Fold #2 ACC: 0.8711, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.6978\n","[DI Valid] Fold #2 ACC: 0.8712, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.7268\n","Fold #3\n","[DI Train] Fold #3 ACC: 0.8711, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.7234\n","[DI Valid] Fold #3 ACC: 0.8712, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.6767\n","Fold #4\n","[DI Train] Fold #4 ACC: 0.8711, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.7132\n","[DI Valid] Fold #4 ACC: 0.8712, PRE: 0.0000, REC: 0.0000, F1: 0.0000, ROC-AUC: 0.7087\n","Fold #5\n","[DI Train] Fold #5 ACC: 0.8718, PRE: 0.7000, REC: 0.0108, F1: 0.0212, ROC-AUC: 0.7541\n","[DI Valid] Fold #5 ACC: 0.8736, PRE: 0.8000, REC: 0.0247, F1: 0.0479, ROC-AUC: 0.7011\n","Avg. roc-auc of validset DI: 0.6922113442200428\n","Var. roc-auc of validset DI: 0.0007523959974091739\n","IVF numeric feature 수: 60\n","IVF category feature 수: 4\n","IVF 전체 feature 수: 64\n","DI numeric feature 수: 24\n","DI category feature 수: 1\n","DI 전체 feature 수: 25\n"]}],"source":["main(config, params_di, params_ivf)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1740570069055,"user":{"displayName":"윤석진","userId":"14953914264612970479"},"user_tz":-540},"id":"4LFlH53fvSLI","outputId":"8ad949d2-6c86-4bf4-9d6e-ad6f3c5065bd"},"outputs":[{"data":{"text/plain":["{'root': '/content/drive/MyDrive/Aimers_6th/Data',\n"," 'train_path': '/content/drive/MyDrive/Aimers_6th/Data/train.csv',\n"," 'test_path': '/content/drive/MyDrive/Aimers_6th/Data/test.csv',\n"," 'submit_path': '/content/drive/MyDrive/Aimers_6th/Data/sample_submission.csv',\n"," 'seed_list': [42],\n"," 'k_fold': 5,\n"," 'model': 'lgb',\n"," 'encoding': None,\n"," 'seed': 42,\n"," 'avg_roc_auc_ivf': 0.7383214411693837,\n"," 'var_roc_auc_ivf': 1.8850283281632053e-06,\n"," 'avg_roc_auc_di': 0.6922113442200428,\n"," 'var_roc_auc_di': 0.0007523959974091739,\n"," 'model_param_di': {'random_state': 42,\n","  'objective': 'binary',\n","  'n_jobs': 1,\n","  'verbosity': -1,\n","  'early_stopping_rounds': 10,\n","  'deterministic': True,\n","  'n_estimators': 910,\n","  'learning_rate': 0.2511885407801018,\n","  'num_leaves': 28,\n","  'max_depth': 4,\n","  'min_child_samples': 56,\n","  'subsample': 0.10122821600860445,\n","  'colsample_bytree': 0.6337550995282828,\n","  'reg_alpha': 0.40455183633441194,\n","  'reg_lambda': 0.000689949085617777},\n"," 'model_param_ivf': {'random_state': 42,\n","  'objective': 'binary',\n","  'n_jobs': 1,\n","  'verbosity': -1,\n","  'early_stopping_rounds': 10,\n","  'deterministic': True,\n","  'n_estimators': 748,\n","  'learning_rate': 0.08840853796420356,\n","  'num_leaves': 64,\n","  'max_depth': 5,\n","  'min_child_samples': 58,\n","  'subsample': 0.7448154771558511,\n","  'colsample_bytree': 0.390303271980168,\n","  'reg_alpha': 9.85421725516684,\n","  'reg_lambda': 0.0011651450136949582}}"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G6GyG-yMcn41","outputId":"f8af836f-9b8a-408f-9f9b-9de52fe3fc87"},"outputs":[{"name":"stdout","output_type":"stream","text":["train data 수: 256351\n","test data 수: 90067\n","submission data 수: 90067\n","data 수: 256351\n","시술유형 IVF train data 수: 250060\n","시술유형 DI train data 수: 6291\n","data 수: 90067\n","시술유형 IVF test data 수: 87891\n","시술유형 DI test data 수: 2176\n"]}],"source":["# read data set\n","df_train, df_test, df_sub = read_data(config)\n","\n","# ivf di split\n","df_train_ivf, df_train_di = df_ivf_di_split(df_train, is_train = True)\n","df_test_ivf, df_test_di = df_ivf_di_split(df_test, is_train = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVQIHe7WBL_k"},"outputs":[],"source":["unique_counts = {column: df_train_ivf[column].nunique() for column in df_train_ivf.columns}\n","for column, count in unique_counts.items():\n","    print(f\"{column}: {count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcsFotf1LWvB","outputId":"35e91cc6-95e8-4926-a9fb-cc0dcce56fd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["시술 시기 코드: 7\n","시술 당시 나이: 6\n","임신 시도 또는 마지막 임신 경과 연수: 19\n","특정 시술 유형: 5\n","배란 자극 여부: 2\n","배란 유도 유형: 1\n","단일 배아 이식 여부: 0\n","착상 전 유전 검사 사용 여부: 0\n","착상 전 유전 진단 사용 여부: 0\n","남성 주 불임 원인: 2\n","남성 부 불임 원인: 2\n","여성 주 불임 원인: 2\n","여성 부 불임 원인: 2\n","부부 주 불임 원인: 2\n","부부 부 불임 원인: 2\n","불명확 불임 원인: 2\n","불임 원인 - 난관 질환: 2\n","불임 원인 - 남성 요인: 2\n","불임 원인 - 배란 장애: 2\n","불임 원인 - 여성 요인: 1\n","불임 원인 - 자궁경부 문제: 1\n","불임 원인 - 자궁내막증: 2\n","불임 원인 - 정자 농도: 2\n","불임 원인 - 정자 면역학적 요인: 1\n","불임 원인 - 정자 운동성: 1\n","불임 원인 - 정자 형태: 2\n","배아 생성 주요 이유: 0\n","총 시술 횟수: 7\n","클리닉 내 총 시술 횟수: 7\n","IVF 시술 횟수: 7\n","DI 시술 횟수: 7\n","총 임신 횟수: 6\n","IVF 임신 횟수: 4\n","DI 임신 횟수: 6\n","총 출산 횟수: 4\n","IVF 출산 횟수: 3\n","DI 출산 횟수: 4\n","총 생성 배아 수: 0\n","미세주입된 난자 수: 0\n","미세주입에서 생성된 배아 수: 0\n","이식된 배아 수: 0\n","미세주입 배아 이식 수: 0\n","저장된 배아 수: 0\n","미세주입 후 저장된 배아 수: 0\n","해동된 배아 수: 0\n","해동 난자 수: 0\n","수집된 신선 난자 수: 0\n","저장된 신선 난자 수: 0\n","혼합된 난자 수: 0\n","파트너 정자와 혼합된 난자 수: 0\n","기증자 정자와 혼합된 난자 수: 0\n","난자 출처: 1\n","정자 출처: 1\n","난자 기증자 나이: 1\n","정자 기증자 나이: 7\n","동결 배아 사용 여부: 0\n","신선 배아 사용 여부: 0\n","기증 배아 사용 여부: 0\n","대리모 여부: 0\n","PGD 시술 여부: 0\n","PGS 시술 여부: 0\n","난자 채취 경과일: 0\n","난자 해동 경과일: 0\n","난자 혼합 경과일: 0\n","배아 이식 경과일: 0\n","배아 해동 경과일: 0\n","임신 성공 여부: 2\n"]}],"source":["unique_counts = {column: df_train_di[column].nunique() for column in df_train_di.columns}\n","for column, count in unique_counts.items():\n","    print(f\"{column}: {count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_WwgWpWCIrim"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yuXvIi42puRZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01jBJoKIpuUT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFyzCOFDpuXE"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2DgpvFIkpuZg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFGUNegXpubY"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":0}