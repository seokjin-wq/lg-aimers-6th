{"cells":[{"cell_type":"markdown","metadata":{"id":"qu7nrq41QJiL"},"source":["### Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3xv7hYGTi4A"},"outputs":[],"source":["!pip install category_encoders\n","!pip install catboost"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4ey8-1l_QJiO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739100144478,"user_tz":-540,"elapsed":12180,"user":{"displayName":"유승태","userId":"01030021726785625805"}},"outputId":"eb6ffdc3-0570-4ac4-d304-3a6d1f7b3166"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]}],"source":["import random\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import os\n","import json\n","import re\n","\n","from sklearn.linear_model import (\n","    LogisticRegression\n",")\n","\n","from sklearn.ensemble import (\n","    ExtraTreesClassifier,\n","    RandomForestClassifier\n",")\n","\n","from sklearn.metrics import (\n","    accuracy_score,\n","    confusion_matrix,\n","    f1_score,\n","    precision_score,\n","    recall_score,\n","    roc_auc_score\n",")\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","import category_encoders as ce\n","\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","from xgboost import XGBClassifier\n","\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"markdown","metadata":{"id":"I5nWl4UXQJiP"},"source":["### Data Load"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Uoab0X_lQRua","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739100174745,"user_tz":-540,"elapsed":30254,"user":{"displayName":"유승태","userId":"01030021726785625805"}},"outputId":"1e1b298e-dfc7-4ecc-bbfe-331ce246a784"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8x1vnRQ8Qwkg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739100174749,"user_tz":-540,"elapsed":10,"user":{"displayName":"유승태","userId":"01030021726785625805"}},"outputId":"12e88254-d06d-45ea-e264-9c7e043bf9b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/MyDrive/Aimers_6th/Data\n"]}],"source":["import os\n","\n","# 현재 작업 디렉터리 출력\n","print(os.getcwd())\n","\n","data_path = os.path.join(os.getcwd(), 'drive', 'MyDrive', 'Aimers_6th', 'Data')\n","print(data_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739100174750,"user":{"displayName":"유승태","userId":"01030021726785625805"},"user_tz":-540},"id":"cljkaVMJCF58"},"outputs":[],"source":["config = {\n","    'root': data_path\n","    , 'train_path': f'{data_path}/train.csv'\n","    , 'test_path': f'{data_path}/test.csv'\n","    , 'submit_path': f'{data_path}/sample_submission.csv'\n","    , 'seed_list': [42]\n","    , 'k_fold': 5\n","    , 'model': 'lgb'       # cbt, logistic, et, rf, lgb, xgb\n","    , 'encoding': None # None(lgb, xgb, cbt), target, one-hot, ordinal, catboost\n","\n","}"]},{"cell_type":"markdown","metadata":{"id":"SKK9T6wdC7tq"},"source":["### HyperParameter"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1739100174762,"user":{"displayName":"유승태","userId":"01030021726785625805"},"user_tz":-540},"id":"FM3otssjC-ur"},"outputs":[],"source":["# Our best parameters\n","params = {\n","    'logistic': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'max_iter': 300,\n","        'penalty': 'l2'\n","    },\n","\n","    'et': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        'max_samples': 0.5\n","\n","    },\n","\n","    'rf': {\n","        'n_jobs': 1,\n","        'random_state': config['seed_list'][0],\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'min_samples_leaf': 2,\n","        # 'max_samples': 0.5,\n","        'bootstrap': False,\n","\n","    },\n","\n","    'lgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary',\n","        'n_jobs': 1,\n","        'verbosity': -1,\n","        'early_stopping_rounds': 10,\n","        'n_estimators': 300,\n","        'learning_rate': 0.1,\n","        'max_depth': 6,\n","        'reg_lambda': 1,\n","        'subsample': 0.5,\n","        'deterministic': True,\n","    },\n","\n","    'xgb': {\n","        'random_state': config['seed_list'][0],\n","        'objective': 'binary:logistic',\n","        'eval_metric': 'auc',\n","        'n_jobs': 1,\n","        'early_stopping_rounds': 10,\n","        'learning_rate': 0.1,\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'reg_lambda': 1,\n","        'subsample': 0.5,\n","        'enable_categorical': True,\n","        'tree_method': 'hist'\n","\n","    },\n","\n","    'cbt': {\n","        'random_seed': config['seed_list'][0],\n","        'objective': 'Logloss',\n","        'eval_metric': 'AUC',\n","        'auto_class_weights': 'Balanced',\n","        'verbose': 100,\n","        'early_stopping_rounds': 10,\n","        'learning_rate': 0.1,\n","        'n_estimators': 300,\n","        'max_depth': 6,\n","        'l2_leaf_reg': 1,\n","        'min_data_in_leaf': 2,\n","        'subsample': 0.5,\n","        'task_type': 'CPU',\n","        'allow_writing_files': False\n","    }\n","}"]},{"cell_type":"markdown","metadata":{"id":"gwV9ZY6PDFoi"},"source":["### Function"]},{"cell_type":"code","execution_count":171,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1739111996292,"user":{"displayName":"유승태","userId":"01030021726785625805"},"user_tz":-540},"id":"0D-Kj4MNDKIC"},"outputs":[],"source":["def set_seed(seed: int):\n","    # Set the seed for reproducibility.\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","\n","\n","def read_data(config):\n","    # Load training, testing, and submission CSV files\n","    df_train = pd.read_csv(config['train_path']).drop(columns=['ID'])  # train data\n","    df_test = pd.read_csv(config['test_path']).drop(columns=['ID'])    # test data\n","    df_sub = pd.read_csv(config['submit_path'])\n","\n","    print(f'train data 수: {df_train.shape[0]}')\n","    print(f'test data 수: {df_test.shape[0]}')\n","    print(f'submission data 수: {df_sub.shape[0]}')\n","    return df_train, df_test, df_sub\n","\n","def get_clf_eval(y_test, y_proba=None, fold_no=None):\n","    # Calculate and print evaluation metrics and confusion matrix,\n","    # accuracy, precision, recall, f1 and roc_auc score.\n","    # Optionally includes fold number in the output.\n","\n","    # 임계값 0.5 기준 예측값 생성\n","    y_pred = (y_proba >= 0.5).astype(int)\n","\n","    y_test = y_test.values\n","\n","    confusion = confusion_matrix(y_test, y_pred)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    roc_auc = roc_auc_score(y_test, y_proba)  # ROC-AUC는 확률값 그대로 사용\n","\n","    fold_info = f'Fold #{fold_no}' if fold_no is not None else ''\n","    print(f'{fold_info} ACC: {accuracy:.4f}, PRE: {precision:.4f}, REC: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}')\n","    return roc_auc\n","\n","\n","# Categorical variable encoding method.\n","def category_encoding(df_train, df_test, base_num_features, base_cat_features, config):\n","    target = '임신 성공 여부'\n","\n","    new_df_train = pd.concat([df_train[base_num_features].copy(), df_train[target]], axis = 1)\n","    new_df_test = df_test[base_num_features].copy()\n","\n","    print(f'category 변수 인코딩: {config[\"encoding\"]}')\n","\n","    if config['encoding'] == 'target':\n","        encoder = ce.TargetEncoder(cols=base_cat_features)\n","\n","    elif config['encoding'] == 'ordinal':\n","        encoder = ce.OrdinalEncoder(cols=base_cat_features)\n","\n","    elif config['encoding'] == 'catboost':\n","        encoder = ce.CatBoostEncoder(cols=base_cat_features)#, random_state=config['seed'])\n","\n","    if config['encoding'] in ['target', 'ordinal', 'catboost']:\n","        encoder.fit(df_train[base_cat_features], df_train[target])\n","        new_df_train[base_cat_features] = encoder.transform(df_train[base_cat_features])\n","        new_df_test[base_cat_features] = encoder.transform(df_test[base_cat_features])\n","\n","    elif config['encoding'] == 'one-hot':\n","        encoder = ce.OneHotEncoder(cols=base_cat_features, use_cat_names = True)\n","        encoder.fit(df_train[base_cat_features], df_train[target])\n","        result_tr = encoder.transform(df_train[base_cat_features])\n","        result_te = encoder.transform(df_test[base_cat_features])\n","\n","        result_tr.columns = result_tr.columns.str.replace(r'[^ㄱ-ㅎ가-힣A-Za-z0-9_]', '_', regex=True)\n","        result_te.columns = result_te.columns.str.replace(r'[^ㄱ-ㅎ가-힣A-Za-z0-9_]', '_', regex=True)\n","\n","        new_df_train = pd.concat([new_df_train, result_tr], axis = 1)\n","        new_df_test = pd.concat([new_df_test, result_te], axis = 1)\n","\n","    elif config['encoding'] is None:\n","        new_df_train = pd.concat([new_df_train, df_train[base_cat_features]], axis = 1)\n","        new_df_test = pd.concat([new_df_test, df_test[base_cat_features]], axis = 1)\n","\n","    _, base_cat_features, base_features = make_feature_lists(new_df_train)\n","\n","    return new_df_train, new_df_test, base_cat_features, base_features\n","\n","# # 변환 함수: 1이 있는 feature를 문자열 조합으로 변환\n","def multi_hot_to_combined_label(row):\n","    return \" \".join(row.index[row == 1].tolist())\n","\n","def feature_engineering(df_input, is_train=False):\n","    df = df_input.copy()\n","\n","    if is_train:\n","        print(f'중복 제거 전 train data 수: {df.shape[0]}')\n","    else:\n","        print(f'중복 제거 전 test data 수: {df.shape[0]}')\n","\n","    # drop_duplicates\n","    df = df.drop_duplicates(keep='first')\n","\n","    if is_train:\n","        print(f'중복 제거 후 train data 수: {df.shape[0]}')\n","    else:\n","        print(f'중복 제거 후 test data 수: {df.shape[0]}')\n","\n","    # # 불임 원인 multi hot -> 하나의 feature\n","\n","    # infertility_columns = [column for column in df.columns if '불임 원인' in column]\n","\n","    # # dot()을 사용하여 1이 있는 컬럼을 결합 (각 feature 사이에 공백 추가)\n","    # df['불임 원인 종합'] = df[infertility_columns].dot(pd.Index([f'{col.replace(\"불임 원인\", \"\").replace(\" \", \"\")} ' for col in infertility_columns])).str.strip()\n","\n","    # # 한글만 남기고 나머지 문자 제거 (정규 표현식 사용)\n","    # df['불임 원인 종합'] = df['불임 원인 종합'].apply(lambda x: re.sub(r'[^가-힣 ]', '', x))\n","\n","    # # split()과 join()을 사용하여 공백을 ','로 변경\n","    # df['불임 원인 종합'] = df['불임 원인 종합'].apply(lambda x: ', '.join(x.split()))\n","\n","    # df = df.drop(columns=infertility_columns)\n","\n","    return df\n","\n","def make_feature_lists(df):\n","    base_features = []     # all features except target variable.\n","    base_num_features = [] # numerical features\n","    base_cat_features = [] # categorical features\n","\n","    for feat in df.columns:\n","        # skip the target\n","        if feat == '임신 성공 여부':\n","            continue\n","\n","        base_features.append(feat)\n","\n","        if df[feat].dtype in ['object', 'category']:\n","            base_cat_features.append(feat)\n","        else:\n","            base_num_features.append(feat)\n","\n","    # infertility_columns = [column for column in df.columns if '불임 원인' in column]\n","\n","    removal_features = {\n","            'ID', '불임 원인 - 여성 요인', '불임 원인 - 정자 면역학적 요인', '불임 원인 - 자궁경부 문제', '불임 원인 - 정자 형태', '남성 주 불임 원인', '여성 주 불임 원인'\n","    }\n","\n","    # removal_features.update(infertility_columns)\n","\n","    # remove the specified features\n","    base_num_features = [i for i in base_num_features if i not in removal_features]\n","    base_cat_features = [i for i in base_cat_features if i not in removal_features]\n","    base_features = [i for i in base_features if i not in removal_features]\n","\n","    print(f'numeric feature 수: {len(base_num_features)}')\n","    print(f'category feature 수: {len(base_cat_features)}')\n","    print(f'전체 feature 수: {len(base_features)}')\n","\n","    return base_num_features, base_cat_features, base_features\n","\n","def filling_missing_values(df_input, base_cat_features, base_num_features, config):\n","    df = df_input.copy()\n","\n","    # Fill missing values for categorical features with 'Unknown' and ensure their data type is string.\n","    for base_cat_feat in base_cat_features:\n","        df[base_cat_feat] = df[base_cat_feat].astype(str)\n","        df[base_cat_feat] = df[base_cat_feat].fillna('알 수 없음')\n","\n","        if config['encoding'] is None:\n","            df[base_cat_feat] = df[base_cat_feat].astype('category')\n","\n","\n","    # Fill missing values for numerical features with -1.\n","    for base_num_feat in base_num_features:\n","        df[base_num_feat] = df[base_num_feat].fillna(-1)\n","\n","    return df\n","\n","\n","def model_kfold(df, config, params, base_features, base_cat_features):\n","    target = '임신 성공 여부'\n","\n","    skf = StratifiedKFold(n_splits=config['k_fold'], shuffle=True, random_state=config['seed'])\n","    models = []       # trained models\n","    roc_auc_scores = []  # roc_auc_scores for validation sets\n","\n","    model_params = params[config['model']]\n","\n","    for k_fold, (train_idx, valid_idx) in enumerate(skf.split(df[base_features], df[target])):\n","        print(f'Fold #{k_fold + 1}')\n","        X_train, y_train = df[base_features].iloc[train_idx], df[target].iloc[train_idx]\n","        X_valid, y_valid = df[base_features].iloc[valid_idx], df[target].iloc[valid_idx]\n","\n","        if config['model'] == 'logistic':\n","            model = LogisticRegression(**model_params)\n","\n","        elif config['model'] == 'et':\n","            model = ExtraTreesClassifier(**model_params)\n","\n","        elif config['model'] == 'rf':\n","            model = RandomForestClassifier(**model_params)\n","\n","        if config['model'] in ['logistic', 'et', 'rf']:\n","            model.fit(X_train, y_train)\n","\n","        elif config['model'] == 'lgb':\n","            model = LGBMClassifier(**model_params)\n","\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                eval_metric='auc',\n","                categorical_feature=base_cat_features, # specify categorical features\n","            )\n","\n","        elif config['model'] == 'xgb':\n","            model = XGBClassifier(**model_params)\n","\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                verbose = 100\n","            )\n","\n","        elif config['model'] == 'cbt':\n","            model = CatBoostClassifier(**model_params)\n","\n","            model.fit(\n","                X_train, y_train,\n","                eval_set=[(X_valid, y_valid)],\n","                cat_features=base_cat_features, # specify categorical features\n","            )\n","\n","        # save the trained model\n","        models.append(model)\n","\n","        # evaluate the model\n","        # --- train-set\n","        print('[Train] ', end='')\n","        y_prob = model.predict_proba(X_train)[:, 1]\n","        _ = get_clf_eval(y_train, y_prob, k_fold + 1)\n","\n","        # --- valid-set\n","        print('[Valid] ', end='')\n","        y_prob = model.predict_proba(X_valid)[:, 1]\n","        roc_auc_score = get_clf_eval(y_valid, y_prob, k_fold + 1)\n","\n","        roc_auc_scores.append(roc_auc_score)\n","\n","    avg_roc_auc = np.mean(roc_auc_scores)\n","    var_roc_auc = np.var(roc_auc_scores)\n","    print(f'Avg. roc-auc of validset: {avg_roc_auc}')\n","    print(f'Var. roc-auc of validset: {var_roc_auc}')\n","\n","    return models, avg_roc_auc, var_roc_auc\n","\n","def kfold_submission(df_test, df_sub, models, config):\n","    feat_importance_path = f\"{config['root']}/FeatureImportance\"\n","    submission_path = f\"{config['root']}/Submission\"\n","    json_path = f\"{config['root']}/Json\"\n","\n","    if not os.path.exists(feat_importance_path):\n","        os.makedirs(feat_importance_path)\n","\n","    if not os.path.exists(submission_path):\n","        os.makedirs(submission_path)\n","\n","    if not os.path.exists(json_path):\n","        os.makedirs(json_path)\n","\n","    # get current date and time\n","    now = datetime.now()\n","\n","    # record the year, month, day, hour, and minute for naming files.\n","    year = now.year\n","    month = now.month\n","    day = now.day\n","    hour = now.hour\n","    minute = now.minute\n","\n","    # file format\n","    submission_time = f\"{year:04d}{month:02d}{day:02d}_{hour:02d}{minute:02d}\"[2:]\n","    target = 'probability'\n","\n","    # apply feature engineering\n","    base_num_features, base_cat_features, base_features = make_feature_lists(df_test)\n","    df_test = filling_missing_values(df_test, base_cat_features, base_num_features, config)\n","    X_test = df_test[base_features]\n","\n","    # dataframe for feature importances\n","    df_feature_importance_all = pd.DataFrame({'features': base_features})\n","\n","    y_probs = 0\n","\n","    for i, model in enumerate(models):\n","        y_probs += model.predict_proba(X_test)[:, 1] / len(models)\n","\n","        # save feature importance of current model\n","        if config['model'] in ['logistic']:\n","            df_feature_importance_all[f'model_{i}'] = model.coef_.squeeze()\n","\n","        elif config['model'] in ['et', 'rf', 'lgb', 'xgb']:\n","            df_feature_importance_all[f'model_{i}'] = model.feature_importances_\n","\n","        elif config['model'] == 'cbt':\n","            df_feature_importance_all[f'model_{i}'] = model.get_feature_importance()\n","\n","\n","    df_sub[target] = y_probs\n","\n","    # save submission file as CSV\n","    df_sub.to_csv(f\"{submission_path}/{submission_time}_{config['model']}_{config['encoding']}_submission.csv\", index=False)\n","\n","    # compute avarege, rank\n","    df_feature_importance_all['average'] = df_feature_importance_all.iloc[:, 1:].mean(axis=1).values\n","    df_feature_importance_all['rank'] = df_feature_importance_all['average'].rank(ascending=False)\n","\n","    # save the feature importance as CSV\n","    df_feature_importance_all.to_csv(f'{feat_importance_path}/feat_import_{submission_time}_{config[\"model\"]}_{config[\"encoding\"]}.csv', index=False)\n","\n","    # save parameters as JSON\n","    json_data = json.dumps(config, indent=4)\n","\n","    with open(f'{json_path}/{submission_time}_{config[\"model\"]}_{config[\"encoding\"]}.json', 'w') as file:\n","        file.write(json_data)"]},{"cell_type":"markdown","metadata":{"id":"3d4zUcXXQJiQ"},"source":["### Data Pre-processing"]},{"cell_type":"code","execution_count":172,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1739111997424,"user":{"displayName":"유승태","userId":"01030021726785625805"},"user_tz":-540},"id":"7wSJYvkYESQv"},"outputs":[],"source":["def main(config, params):\n","    models = []\n","\n","\n","    for seed in config['seed_list']:\n","        config['seed'] = seed\n","        params['random_seed'] = seed\n","\n","        # set seed\n","        set_seed(config['seed'])\n","\n","        # read data set\n","        df_train, df_test, df_sub = read_data(config)\n","\n","        # feature engineering (train,test)\n","        df_train = feature_engineering(df_train, is_train=True)\n","        df_test = feature_engineering(df_test, is_train=False)\n","\n","        # feature list 생성 (train)\n","        base_num_features, base_cat_features, base_features = make_feature_lists(df_train)\n","\n","        # 결측치 처리\n","        df_train = filling_missing_values(df_train, base_cat_features, base_num_features, config)\n","\n","        # encoding\n","        df_train, df_test, base_cat_features, base_features = category_encoding(df_train, df_test, base_num_features, base_cat_features, config)\n","\n","        # check model performance\n","        model, avg_roc_auc, var_roc_auc = model_kfold(df_train, config, params, base_features, base_cat_features)\n","\n","        config['avg_roc_auc'] = avg_roc_auc\n","        config['var_roc_auc'] = var_roc_auc\n","\n","        models.extend(model)\n","\n","    config['model_param'] = params[config['model']]\n","\n","    # submission\n","    kfold_submission(df_test, df_sub, models, config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaZgJXIyEVDj","collapsed":true},"outputs":[],"source":["main(config, params)"]},{"cell_type":"code","source":[],"metadata":{"id":"wB8yX-ndiLIO","executionInfo":{"status":"aborted","timestamp":1739102117989,"user_tz":-540,"elapsed":5,"user":{"displayName":"유승태","userId":"01030021726785625805"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":0}